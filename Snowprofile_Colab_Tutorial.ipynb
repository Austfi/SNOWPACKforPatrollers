{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Snowprofile: Read, Inspect, Plot, and Export CAAML 6\n",
        "\n",
        "This tutorial teaches avalanche practitioners how to use the `snowprofile` Python package with CAAML v6 files in Google Colab. You'll learn to read snow profile data, explore the SnowProfile object structure, analyze profiles, create visualizations, and export back to CAAML format.\n",
        "\n",
        "**Demo File**: This tutorial uses `snowprofiles/example_profile.caaml` as the example file. When running in Colab, the notebook will automatically download it from the repository. When running locally from the repository, it will use the file directly.\n",
        "\n",
        "## Goals and Workflow\n",
        "\n",
        "1. **Install** → Install `snowprofile` and dependencies\n",
        "2. **Read CAAML** → Load a user-provided CAAML v6 file (or use the example file)\n",
        "3. **Explore** → Inspect the SnowProfile object structure and data\n",
        "4. **Analyze** → Compute temperature gradients and examine stratigraphy\n",
        "5. **Visualize** → Create plots using built-in plotting functions\n",
        "6. **Export** → Write profiles back to CAAML format\n",
        "\n",
        "## Units and Conventions\n",
        "\n",
        "- **Heights**: Measured in meters (SI units)\n",
        "- **Vertical coordinate**: Zero is at the bottom of the profile\n",
        "- **Unit conversions**: The `snowprofile` package handles unit conversions automatically on read/write operations\n",
        "- **CAAML versions**: Reader supports up to CAAML 6.0.5; writer supports 6.0.5 (default) and 6.0.6\n",
        "\n",
        "## References\n",
        "\n",
        "- Package: `pip install snowprofile`\n",
        "- CAAML I/O: `snowprofile.io.read_caaml6_xml`, `snowprofile.io.write_caaml6_xml`\n",
        "- Plotting: `snowprofile.plot.plot_simple`, `snowprofile.plot.plot_full`, `snowprofile.plot.plot_utils`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠ Not running in Colab - some features may not work\n",
            "✓ Matplotlib backend: Agg\n"
          ]
        }
      ],
      "source": [
        "# Environment checks\n",
        "import sys\n",
        "\n",
        "# Confirm we're in Colab\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "if IN_COLAB:\n",
        "    print(\"✓ Running in Google Colab\")\n",
        "else:\n",
        "    print(\"⚠ Not running in Colab - some features may not work\")\n",
        "\n",
        "# Set matplotlib inline and silence warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure matplotlib for inline plotting (Colab handles this automatically)\n",
        "import matplotlib\n",
        "if IN_COLAB:\n",
        "    matplotlib.use('inline')  # Colab uses inline by default\n",
        "else:\n",
        "    matplotlib.use('Agg')  # Non-interactive backend for local testing\n",
        "print(f\"✓ Matplotlib backend: {matplotlib.get_backend()}\")\n",
        "\n",
        "# Enable inline plotting\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'snowprofile' has no attribute '__version__'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Verify installation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msnowprofile\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ snowprofile version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnowprofile\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'snowprofile' has no attribute '__version__'"
          ]
        }
      ],
      "source": [
        "# Install snowprofile and dependencies\n",
        "%pip install -q snowprofile pandas numpy matplotlib rich\n",
        "\n",
        "# Verify installation\n",
        "import snowprofile\n",
        "print(f\"✓ snowprofile version: {snowprofile.__version__}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# snowprofile imports\n",
        "import snowprofile\n",
        "from snowprofile import io as spio\n",
        "from snowprofile import plot as spplot\n",
        "from snowprofile.plot import plot_utils as sppu\n",
        "\n",
        "# Optional rich printing with fallback\n",
        "try:\n",
        "    from rich import print as rprint\n",
        "except ImportError:\n",
        "    rprint = print\n",
        "\n",
        "print(\"✓ All imports successful\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data intake: Upload CAAML file or use example file\n",
        "\n",
        "# Option A: Use example file from repository (for tutorial/demo)\n",
        "# If running from the repository, use the example file\n",
        "EXAMPLE_FILE = Path(\"snowprofiles/example_profile.caaml\")\n",
        "\n",
        "if EXAMPLE_FILE.exists():\n",
        "    CAAML_PATH = EXAMPLE_FILE\n",
        "    print(f\"✓ Using example file: {CAAML_PATH}\")\n",
        "    print(f\"  This is a demo CAAML v6 file from the repository\")\n",
        "elif IN_COLAB:\n",
        "    # Option B: Download example file from repository (Colab)\n",
        "    print(\"Downloading example CAAML file from repository...\")\n",
        "    import urllib.request\n",
        "    example_url = \"https://raw.githubusercontent.com/Austfi/SNOWPACKforPatrollers/main/snowprofiles/example_profile.caaml\"\n",
        "    CAAML_PATH = Path(\"example_profile.caaml\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(example_url, str(CAAML_PATH))\n",
        "        print(f\"✓ Downloaded example file: {CAAML_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Could not download example file: {e}\")\n",
        "        print(\"Falling back to file upload...\")\n",
        "        # Option C: Colab file upload (fallback)\n",
        "        from google.colab import files\n",
        "        print(\"Upload a CAAML v6 file (.caaml or .xml):\")\n",
        "        uploaded = files.upload()\n",
        "        CAAML_PATH = Path(next(iter(uploaded)))\n",
        "        print(f\"✓ Uploaded: {CAAML_PATH}\")\n",
        "else:\n",
        "    # Option D: Local testing - set path here\n",
        "    CAAML_PATH = Path(\"example.caaml\")  # Modify as needed\n",
        "    print(f\"⚠ Using local path: {CAAML_PATH}\")\n",
        "    print(f\"  For demo, ensure snowprofiles/example_profile.caaml exists\")\n",
        "\n",
        "# Verify file exists\n",
        "assert CAAML_PATH.exists(), f\"File not found: {CAAML_PATH}\"\n",
        "print(f\"✓ File exists: {CAAML_PATH.absolute()}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CAAML sanity check - Light XML parsing before using snowprofile\n",
        "\n",
        "tree = ET.parse(CAAML_PATH)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Detect CAAML v6 namespace\n",
        "CAAML_NS_URIS = [\n",
        "    \"http://caaml.org/Schemas/SnowProfileIACS/v6.0.3\",\n",
        "    \"http://caaml.org/Schemas/SnowProfileIACS/v6.0.4\",\n",
        "    \"http://caaml.org/Schemas/SnowProfileIACS/v6.0.5\",\n",
        "    \"http://caaml.org/Schemas/SnowProfileIACS/v6.0.6\"\n",
        "]\n",
        "\n",
        "# Find namespace (common prefixes)\n",
        "ns_uri = None\n",
        "for uri in CAAML_NS_URIS:\n",
        "    # Try common namespace prefixes\n",
        "    for prefix in ['', '{', 'caaml:', '{caaml:']:\n",
        "        test_ns = f\"{{{uri}}}\" if prefix == '{' else uri\n",
        "        if test_ns in root.tag or uri in root.tag:\n",
        "            ns_uri = uri\n",
        "            break\n",
        "    if ns_uri:\n",
        "        break\n",
        "\n",
        "if not ns_uri:\n",
        "    # Try to extract from root tag\n",
        "    if '}' in root.tag:\n",
        "        ns_uri = root.tag.split('}')[0][1:]\n",
        "    else:\n",
        "        raise ValueError(\"Could not detect CAAML v6 namespace. Is this a CAAML v6 file?\")\n",
        "\n",
        "print(f\"✓ CAAML namespace detected: {ns_uri}\")\n",
        "\n",
        "# Count layers and temperature observations\n",
        "ns = {\"caaml\": ns_uri}\n",
        "layer_count = len(root.findall(\".//caaml:Layer\", ns))\n",
        "temp_obs_count = len(root.findall(\".//caaml:tempProfile\", ns))\n",
        "\n",
        "print(f\"✓ Layers found: {layer_count}\")\n",
        "print(f\"✓ Temperature profiles found: {temp_obs_count}\")\n",
        "\n",
        "# Extract timePosition if present\n",
        "time_elem = root.find(\".//caaml:timePosition\", ns)\n",
        "if time_elem is not None:\n",
        "    time_str = time_elem.text or time_elem.get('value', 'N/A')\n",
        "    print(f\"✓ Time position: {time_str}\")\n",
        "else:\n",
        "    print(\"⚠ No timePosition found\")\n",
        "\n",
        "# Gather all loc attribute values\n",
        "loc_values = []\n",
        "for elem in root.iter():\n",
        "    if \"loc\" in elem.attrib:\n",
        "        loc_values.append(elem.attrib[\"loc\"])\n",
        "\n",
        "if loc_values:\n",
        "    from collections import Counter\n",
        "    loc_freq = Counter(loc_values)\n",
        "    print(f\"\\n✓ Loc attribute frequency:\")\n",
        "    for loc, count in loc_freq.most_common():\n",
        "        print(f\"  {loc}: {count}\")\n",
        "    \n",
        "    # Check for non-standard tags\n",
        "    standard = {\"T\", \"M\", \"B\"}\n",
        "    non_standard = set(loc_freq.keys()) - standard\n",
        "    if non_standard:\n",
        "        print(f\"\\n⚠ Non-standard loc values found: {non_standard}\")\n",
        "        print(\"  These may cause validation errors. The library validates tables strictly.\")\n",
        "        print(\"  Standard values are: T (top), M (middle), B (bottom)\")\n",
        "else:\n",
        "    print(\"⚠ No loc attributes found\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: sanitize_caaml_loc\n",
        "# This function normalizes non-standard loc attribute values to {T, M, B} or removes them\n",
        "\n",
        "def sanitize_caaml_loc(in_path: Path, out_path: Path, ns_uri=\"http://caaml.org/Schemas/SnowProfileIACS/v6.0.3\"):\n",
        "    \"\"\"\n",
        "    Sanitize CAAML file by normalizing loc attributes to standard values {T, M, B}.\n",
        "    \n",
        "    Some exporters use loc=\"Surface\", loc=\"Bottom\", etc. This function:\n",
        "    - Maps common variants to standard values (Surface/Top→T, Bottom→B, Mid/Middle→M)\n",
        "    - Removes unknown loc values to avoid validation errors\n",
        "    \"\"\"\n",
        "    ns = \"{\"+ns_uri+\"}\"\n",
        "    tree = ET.parse(in_path)\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    mapping = {\n",
        "        \"S\": \"T\", \"Surface\": \"T\", \"Top\": \"T\", \"top\": \"T\",\n",
        "        \"P\": \"B\", \"Bottom\": \"B\", \"Btm\": \"B\", \"bottom\": \"B\",\n",
        "        \"L\": \"M\", \"Mid\": \"M\", \"Middle\": \"M\", \"middle\": \"M\"\n",
        "    }\n",
        "    \n",
        "    for elem in root.iter():\n",
        "        if \"loc\" in elem.attrib:\n",
        "            v = elem.attrib[\"loc\"]\n",
        "            if v in {\"T\",\"M\",\"B\"}: \n",
        "                continue\n",
        "            if v in mapping:\n",
        "                elem.set(\"loc\", mapping[v])\n",
        "            else:\n",
        "                del elem.attrib[\"loc\"]\n",
        "    \n",
        "    tree.write(out_path, encoding=\"utf-8\", xml_declaration=True)\n",
        "    print(f\"✓ Sanitized file written to: {out_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read CAAML file\n",
        "\n",
        "try:\n",
        "    sp = spio.read_caaml6_xml(str(CAAML_PATH))\n",
        "    print(f\"✓ Successfully read CAAML file: {CAAML_PATH.name}\")\n",
        "except ValueError as e:\n",
        "    if \"Unauthorized value for key loc\" in str(e) or \"validation\" in str(e).lower():\n",
        "        print(f\"⚠ Validation error detected: {e}\")\n",
        "        print(\"Attempting to sanitize loc attributes...\")\n",
        "        \n",
        "        # Create sanitized copy\n",
        "        fixed_path = CAAML_PATH.parent / f\"{CAAML_PATH.stem}.fixed{CAAML_PATH.suffix}\"\n",
        "        sanitize_caaml_loc(CAAML_PATH, fixed_path, ns_uri)\n",
        "        \n",
        "        # Retry reading\n",
        "        try:\n",
        "            sp = spio.read_caaml6_xml(str(fixed_path))\n",
        "            print(f\"✓ Successfully read sanitized file: {fixed_path.name}\")\n",
        "            CAAML_PATH = fixed_path  # Update path for reference\n",
        "        except Exception as e2:\n",
        "            raise ValueError(f\"Failed to read even after sanitization: {e2}\")\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "# Verify we have a valid SnowProfile object\n",
        "assert sp is not None, \"Failed to read SnowProfile object\"\n",
        "print(f\"✓ SnowProfile object created successfully\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SnowProfile Summary\n",
        "\n",
        "The SnowProfile object contains time, location, depth/SWE, stratigraphy, and various profile data (temperature, density, hardness, etc.). Let's explore its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SnowProfile summary\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SNOWPROFILE SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Time information\n",
        "print(f\"\\nTime:\")\n",
        "if hasattr(sp, 'record_time') and sp.record_time:\n",
        "    print(f\"  Record time: {sp.record_time}\")\n",
        "if hasattr(sp, 'report_time') and sp.report_time:\n",
        "    print(f\"  Report time: {sp.report_time}\")\n",
        "\n",
        "# Location information\n",
        "print(f\"\\nLocation:\")\n",
        "if hasattr(sp, 'name') and sp.name:\n",
        "    print(f\"  Name: {sp.name}\")\n",
        "if hasattr(sp, 'elevation') and sp.elevation is not None:\n",
        "    print(f\"  Elevation: {sp.elevation} m\")\n",
        "if hasattr(sp, 'aspect') and sp.aspect is not None:\n",
        "    print(f\"  Aspect: {sp.aspect}°\")\n",
        "if hasattr(sp, 'slope') and sp.slope is not None:\n",
        "    print(f\"  Slope: {sp.slope}°\")\n",
        "if hasattr(sp, 'latitude') and sp.latitude is not None:\n",
        "    print(f\"  Latitude: {sp.latitude}°\")\n",
        "if hasattr(sp, 'longitude') and sp.longitude is not None:\n",
        "    print(f\"  Longitude: {sp.longitude}°\")\n",
        "\n",
        "# Profile dimensions\n",
        "print(f\"\\nProfile dimensions:\")\n",
        "if hasattr(sp, 'profile_depth') and sp.profile_depth is not None:\n",
        "    print(f\"  Profile depth: {sp.profile_depth:.2f} m\")\n",
        "if hasattr(sp, 'profile_swe') and sp.profile_swe is not None:\n",
        "    print(f\"  Profile SWE: {sp.profile_swe:.1f} mm\")\n",
        "\n",
        "# Count available profiles\n",
        "print(f\"\\nAvailable profiles:\")\n",
        "profile_types = {\n",
        "    'temperature_profiles': getattr(sp, 'temperature_profiles', None),\n",
        "    'density_profiles': getattr(sp, 'density_profiles', None),\n",
        "    'hardness_profiles': getattr(sp, 'hardness_profiles', None),\n",
        "    'ssa_profiles': getattr(sp, 'ssa_profiles', None),\n",
        "    'strength_profiles': getattr(sp, 'strength_profiles', None),\n",
        "    'lwc_profiles': getattr(sp, 'lwc_profiles', None),\n",
        "    'other_scalar_profiles': getattr(sp, 'other_scalar_profiles', None),\n",
        "    'other_vectorial_profiles': getattr(sp, 'other_vectorial_profiles', None),\n",
        "}\n",
        "\n",
        "for name, profile_list in profile_types.items():\n",
        "    if profile_list is not None:\n",
        "        count = len(profile_list) if isinstance(profile_list, list) else (1 if profile_list else 0)\n",
        "        print(f\"  {name}: {count}\")\n",
        "    else:\n",
        "        print(f\"  {name}: not available\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stratigraphy inspection\n",
        "\n",
        "if hasattr(sp, 'stratigraphy_profile') and sp.stratigraphy_profile is not None:\n",
        "    print(\"✓ Stratigraphy profile available\")\n",
        "    \n",
        "    # Get stratigraphy data\n",
        "    strat_data = sp.stratigraphy_profile\n",
        "    if hasattr(strat_data, 'data'):\n",
        "        df = strat_data.data\n",
        "    elif hasattr(strat_data, 'data_dict'):\n",
        "        import pandas as pd\n",
        "        df = pd.DataFrame(strat_data.data_dict)\n",
        "    else:\n",
        "        df = None\n",
        "    \n",
        "    if df is not None and not df.empty:\n",
        "        print(f\"\\nStratigraphy DataFrame shape: {df.shape}\")\n",
        "        print(f\"\\nFirst few layers:\")\n",
        "        print(df.head())\n",
        "        \n",
        "        # Check for expected columns\n",
        "        expected_cols = ['top_height', 'bottom_height', 'thickness']\n",
        "        has_expected = all(col in df.columns for col in expected_cols)\n",
        "        assert has_expected, f\"Missing expected columns. Found: {list(df.columns)}\"\n",
        "        \n",
        "        # Map hand-hardness strings to numeric for quick stats\n",
        "        hardness_map = {'F': 1, '4F': 2, '1F': 3, 'P': 4, 'K': 5}\n",
        "        if 'hardness' in df.columns:\n",
        "            df['hardness_numeric'] = df['hardness'].map(hardness_map)\n",
        "            print(f\"\\nHand-hardness mapping (conventional indices):\")\n",
        "            for k, v in hardness_map.items():\n",
        "                print(f\"  {k} → {v}\")\n",
        "        \n",
        "        # Sanity check: compare profile_depth vs max layer bottom\n",
        "        if 'bottom_height' in df.columns:\n",
        "            max_bottom = df['bottom_height'].max()\n",
        "            print(f\"\\n✓ Max layer bottom: {max_bottom:.2f} m\")\n",
        "            if hasattr(sp, 'profile_depth') and sp.profile_depth:\n",
        "                print(f\"✓ Profile depth: {sp.profile_depth:.2f} m\")\n",
        "                diff = abs(max_bottom - sp.profile_depth)\n",
        "                if diff > 0.01:\n",
        "                    print(f\"⚠ Difference: {diff:.2f} m\")\n",
        "        \n",
        "        # Histogram of layer thickness\n",
        "        if 'thickness' in df.columns:\n",
        "            import matplotlib.pyplot as plt\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.hist(df['thickness'], bins=20, edgecolor='black')\n",
        "            plt.xlabel('Layer thickness (m)')\n",
        "            plt.ylabel('Frequency')\n",
        "            plt.title('Distribution of Layer Thickness')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.show()\n",
        "    else:\n",
        "        print(\"⚠ Stratigraphy data not available as DataFrame\")\n",
        "else:\n",
        "    print(\"⚠ No stratigraphy profile available\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Temperature Gradient Analysis\n",
        "\n",
        "The temperature gradient indicates how quickly temperature changes with depth. Strong gradients can indicate instability or rapid temperature changes.\n",
        "\n",
        "### Mathematical Formula\n",
        "\n",
        "The temperature gradient is computed using a centered finite-difference approximation:\n",
        "\n",
        "$$\\frac{dT}{dz}\\Big|_{z_i} \\approx \\frac{T_{i+1} - T_{i-1}}{z_{i+1} - z_{i-1}}$$\n",
        "\n",
        "**Units**: °C/m (degrees Celsius per meter)\n",
        "\n",
        "**Context**: \n",
        "- Strong gradients (typically ≥ 10 °C/m) can indicate:\n",
        "  - Rapid temperature changes\n",
        "  - Potential instability\n",
        "  - Temperature inversions\n",
        "  \n",
        "**Note**: Interpretation depends on context - strong gradients near the surface during cold snaps are different from mid-pack gradients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temperature gradient analysis\n",
        "\n",
        "if hasattr(sp, 'temperature_profiles') and sp.temperature_profiles:\n",
        "    temp_profiles = sp.temperature_profiles\n",
        "    if len(temp_profiles) > 0:\n",
        "        # Use first temperature profile\n",
        "        temp_profile = temp_profiles[0]\n",
        "        \n",
        "        # Get data\n",
        "        if hasattr(temp_profile, 'data'):\n",
        "            temp_data = temp_profile.data\n",
        "        elif hasattr(temp_profile, 'data_dict'):\n",
        "            temp_data = pd.DataFrame(temp_profile.data_dict)\n",
        "        else:\n",
        "            temp_data = None\n",
        "        \n",
        "        if temp_data is not None and not temp_data.empty:\n",
        "            # Ensure we have height and temperature columns\n",
        "            if 'height' in temp_data.columns and 'temperature' in temp_data.columns:\n",
        "                # Sort by height\n",
        "                temp_data = temp_data.sort_values('height')\n",
        "                heights = temp_data['height'].values\n",
        "                temps = temp_data['temperature'].values\n",
        "                \n",
        "                # Remove NaN values\n",
        "                valid_mask = ~(np.isnan(heights) | np.isnan(temps))\n",
        "                heights = heights[valid_mask]\n",
        "                temps = temps[valid_mask]\n",
        "                \n",
        "                if len(heights) > 1:\n",
        "                    # Compute gradient using numpy's gradient function\n",
        "                    # edge_order=2 uses second-order accurate differences at boundaries\n",
        "                    dTdz = np.gradient(temps, heights, edge_order=2)\n",
        "                    \n",
        "                    # Create strong gradient flag (≥ 10 °C/m threshold)\n",
        "                    strong_gradient_flag = np.abs(dTdz) >= 10\n",
        "                    \n",
        "                    print(f\"✓ Temperature profile analyzed\")\n",
        "                    print(f\"  Data points: {len(heights)}\")\n",
        "                    print(f\"  Height range: {heights.min():.2f} - {heights.max():.2f} m\")\n",
        "                    print(f\"  Temperature range: {temps.min():.2f} - {temps.max():.2f} °C\")\n",
        "                    print(f\"  Gradient range: {dTdz.min():.2f} - {dTdz.max():.2f} °C/m\")\n",
        "                    print(f\"  Strong gradients (≥10 °C/m): {np.sum(strong_gradient_flag)} points\")\n",
        "                    \n",
        "                    # Plot temperature vs height\n",
        "                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
        "                    \n",
        "                    # Temperature profile\n",
        "                    ax1.plot(temps, heights, 'o-', markersize=4)\n",
        "                    ax1.set_xlabel('Temperature (°C)')\n",
        "                    ax1.set_ylabel('Height (m)')\n",
        "                    ax1.set_title('Temperature Profile')\n",
        "                    ax1.grid(True, alpha=0.3)\n",
        "                    ax1.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
        "                    \n",
        "                    # Temperature gradient\n",
        "                    ax2.plot(dTdz, heights, 'o-', markersize=4, color='orange')\n",
        "                    ax2.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
        "                    ax2.axvline(x=10, color='r', linestyle='--', alpha=0.5, label='±10 °C/m threshold')\n",
        "                    ax2.axvline(x=-10, color='r', linestyle='--', alpha=0.5)\n",
        "                    ax2.set_xlabel('Temperature Gradient (°C/m)')\n",
        "                    ax2.set_ylabel('Height (m)')\n",
        "                    ax2.set_title('Temperature Gradient')\n",
        "                    ax2.grid(True, alpha=0.3)\n",
        "                    ax2.legend()\n",
        "                    \n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                    \n",
        "                    print(\"\\nNote: Heights are in meters, zero at bottom. The library handles unit conversions automatically.\")\n",
        "                else:\n",
        "                    print(\"⚠ Insufficient data points for gradient calculation\")\n",
        "            else:\n",
        "                print(f\"⚠ Missing required columns. Available: {list(temp_data.columns)}\")\n",
        "        else:\n",
        "            print(\"⚠ Temperature data not available\")\n",
        "    else:\n",
        "        print(\"⚠ No temperature profiles available\")\n",
        "else:\n",
        "    print(\"⚠ Temperature profile data not available\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: plot_full_safe\n",
        "# Robust wrapper for plot_full that handles single-Axes edge case\n",
        "\n",
        "def plot_full_safe(sp,\n",
        "                   index_temperature_profiles='all',\n",
        "                   index_density_profiles='all', style_density_profiles='step',\n",
        "                   index_hardness_profiles='all', style_hardness_profiles='step',\n",
        "                   index_impurity_profiles='all', style_impurity_profiles='point',\n",
        "                   index_ssa_profiles='all', style_ssa_profiles='point',\n",
        "                   index_strength_profiles='all', style_strength_profiles='point',\n",
        "                   index_lwc_profiles='all', style_lwc_profiles='step',\n",
        "                   index_scalar_profiles='all',\n",
        "                   **kwargs):\n",
        "    \"\"\"\n",
        "    Safe wrapper for plot_full that handles single-Axes edge case.\n",
        "    \n",
        "    Creates subplots with squeeze=False and flattens via axs.ravel() to avoid\n",
        "    the TypeError: 'Axes' object is not iterable when there's only one subplot.\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    from snowprofile.plot import plot_utils\n",
        "    \n",
        "    to_plot = {\n",
        "        'Stratigraphy profile': {'plot_style':'profile','key':'hardness','xlabel':'Hand hardness','data':sp.stratigraphy_profile,'index':None},\n",
        "        'Hardness profile': {'plot_style':style_hardness_profiles,'key':'hardness','xlabel':'Hardness (N)','data':sp.hardness_profiles,'index':index_hardness_profiles},\n",
        "        'Temperature profile': {'plot_style':'point','key':'temperature','xlabel':'Temperature (°C)','data':sp.temperature_profiles,'index':index_temperature_profiles},\n",
        "        'Density profile': {'plot_style':style_density_profiles,'key':'density','xlabel':'Density (kg/m3)','data':sp.density_profiles,'index':index_density_profiles},\n",
        "        'LWC': {'plot_style':style_lwc_profiles,'key':'lwc','xlabel':'LWC (%)','data':sp.lwc_profiles,'index':index_lwc_profiles},\n",
        "        'Strength profile': {'plot_style':style_strength_profiles,'key':'strength','xlabel':'Strength (N)','data':sp.strength_profiles,'index':index_strength_profiles},\n",
        "        'SSA profile': {'plot_style':style_ssa_profiles,'key':'ssa','xlabel':'SSA (m2/kg)','data':sp.ssa_profiles,'index':index_ssa_profiles},\n",
        "        'Impurity profile': {'plot_style':style_impurity_profiles,'key':'mass_fraction','xlabel':'Impurity mass fraction','data':sp.impurity_profiles,'index':index_impurity_profiles},\n",
        "        'Other scalar profile': {'plot_style':'point','key':'data','xlabel':'Other scalar variable','data':sp.other_scalar_profiles,'index':index_scalar_profiles},\n",
        "    }\n",
        "    step_profiles_key_list = ['hardness']\n",
        "\n",
        "    n_to_plot = 0\n",
        "    for v in to_plot.values():\n",
        "        if v['data'] is not None and (not isinstance(v['data'], list) or (len(v['data'])>0 and v['index'] is not None)):\n",
        "            v['ok'] = True; n_to_plot += 1\n",
        "        else:\n",
        "            v['ok'] = False\n",
        "    if n_to_plot == 0:\n",
        "        raise ValueError(\"Nothing to plot.\")\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=(n_to_plot - 1)//4 + 1,\n",
        "                            ncols=min(n_to_plot, 4),\n",
        "                            figsize=(16,15), sharey=True,\n",
        "                            gridspec_kw={'wspace':0.4},\n",
        "                            squeeze=False)  # squeeze=False prevents single-Axes issue\n",
        "    axes = axs.ravel().tolist()\n",
        "\n",
        "    n = 0\n",
        "    for v in to_plot.values():\n",
        "        if not v['ok']: \n",
        "            continue\n",
        "        common = {'ylabel': 'Height (m)' if n % 4 == 0 else None}\n",
        "        if v['plot_style'] == 'profile':\n",
        "            plot_utils.plot_strati_profile(axes[n], v['data'], xlabel=v['xlabel'], **common, **kwargs)\n",
        "        elif v['plot_style'] == 'point':\n",
        "            plot_utils.plot_point_profile(axes[n], v['data'], v['key'], v['index'], xlabel=v['xlabel'], **common, **kwargs)\n",
        "        elif v['plot_style'] == 'step':\n",
        "            if v['key'] in step_profiles_key_list:\n",
        "                plot_utils.plot_step_profile(axes[n], v['data'], v['key'], v['index'], xlabel=v['xlabel'], **common, **kwargs)\n",
        "            else:\n",
        "                plot_utils.plot_vline_profile(axes[n], v['data'], v['key'], v['index'], xlabel=v['xlabel'], **common, **kwargs)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown style {v['plot_style']}\")\n",
        "        n += 1\n",
        "    return fig\n",
        "\n",
        "print(\"✓ plot_full_safe helper function defined\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot using built-in functions\n",
        "\n",
        "# Quick overview plot\n",
        "print(\"Plotting simple overview...\")\n",
        "try:\n",
        "    spplot.plot_simple(sp)\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error in plot_simple: {e}\")\n",
        "\n",
        "# Full plot using safe wrapper\n",
        "print(\"\\nPlotting full profile (safe wrapper)...\")\n",
        "try:\n",
        "    fig = plot_full_safe(sp)\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error in plot_full_safe: {e}\")\n",
        "    print(\"This may happen if no profiles are available to plot.\")\n",
        "\n",
        "# Custom stratigraphy panel\n",
        "if hasattr(sp, 'stratigraphy_profile') and sp.stratigraphy_profile is not None:\n",
        "    print(\"\\nCustom stratigraphy panel...\")\n",
        "    fig, ax = plt.subplots(figsize=(5, 6))\n",
        "    try:\n",
        "        sppu.plot_strati_profile(ax, sp.stratigraphy_profile, \n",
        "                                xlabel=\"Hand hardness\", \n",
        "                                ylabel=\"Height (m)\", \n",
        "                                use_hardness=True)\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error plotting stratigraphy: {e}\")\n",
        "else:\n",
        "    print(\"⚠ No stratigraphy profile available for custom plot\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export back to CAAML\n",
        "\n",
        "# Create outputs directory\n",
        "output_dir = Path(\"outputs\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Export to CAAML 6.0.5 (default)\n",
        "out_path = output_dir / \"profile_out.caaml\"\n",
        "try:\n",
        "    spio.write_caaml6_xml(sp, str(out_path), version=\"6.0.5\", indent=True)\n",
        "    print(f\"✓ Exported to CAAML 6.0.5: {out_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error exporting to 6.0.5: {e}\")\n",
        "\n",
        "# Also export to CAAML 6.0.6 (writer supports both versions)\n",
        "out_path_606 = output_dir / \"profile_out_606.caaml\"\n",
        "try:\n",
        "    spio.write_caaml6_xml(sp, str(out_path_606), version=\"6.0.6\", indent=True)\n",
        "    print(f\"✓ Exported to CAAML 6.0.6: {out_path_606}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error exporting to 6.0.6: {e}\")\n",
        "\n",
        "# Download link for Colab\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    print(\"\\nDownload options:\")\n",
        "    if out_path.exists():\n",
        "        print(f\"  Downloading {out_path.name}...\")\n",
        "        files.download(str(out_path))\n",
        "    if out_path_606.exists():\n",
        "        print(f\"  Downloading {out_path_606.name}...\")\n",
        "        files.download(str(out_path_606))\n",
        "\n",
        "print(\"\\nNote: Some user-defined data may not round-trip perfectly. The writer preserves core profile data but may lose custom metadata.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JSON / dict views\n",
        "\n",
        "from snowprofile.io import to_dict, to_json\n",
        "\n",
        "# Convert to dictionary\n",
        "sp_dict = to_dict(sp)\n",
        "print(\"Top-level keys in dictionary representation:\")\n",
        "print(list(sp_dict.keys())[:10])  # Show first 10 keys\n",
        "if len(sp_dict) > 10:\n",
        "    print(f\"... and {len(sp_dict) - 10} more keys\")\n",
        "\n",
        "# Convert to JSON\n",
        "sp_json = to_json(sp)\n",
        "print(f\"\\nJSON representation length: {len(sp_json)} characters\")\n",
        "print(f\"JSON preview (first 200 chars):\\n{sp_json[:200]}...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Merge Profiles\n",
        "\n",
        "If you have a second CAAML file, you can merge profiles using `SnowProfile.merge()`. This is useful for combining observations from different times or locations.\n",
        "\n",
        "Example code (commented out - uncomment if you have a second file):\n",
        "\n",
        "```python\n",
        "# Load second profile\n",
        "# sp2 = spio.read_caaml6_xml(str(CAAML_PATH_2))\n",
        "# \n",
        "# # Merge profiles\n",
        "# sp_merged = sp.merge(sp2)\n",
        "# \n",
        "# # Export merged profile\n",
        "# spio.write_caaml6_xml(sp_merged, \"outputs/merged_profile.caaml\", version=\"6.0.5\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try-It Exercises\n",
        "\n",
        "Here are some exercises to practice with the `snowprofile` package:\n",
        "\n",
        "1. **Change temperature profile index**: Modify the temperature gradient analysis to use a different temperature profile (e.g., `temp_profiles[1]` if available)\n",
        "\n",
        "2. **Import density CSV**: Use `snowprofile.io.profile_csv.read_csv_profile()` to import a density profile from CSV and merge it with your CAAML profile. See the I/O CSV documentation section for details.\n",
        "\n",
        "3. **Compare CAAML versions**: Export the same profile as both 6.0.5 and 6.0.6, then compare the XML files to see differences.\n",
        "\n",
        "4. **Compute SWE from density**: Use a density profile to compute Snow Water Equivalent (SWE) by integrating density × thickness:\n",
        "   ```python\n",
        "   # SWE = ∫ density(z) dz\n",
        "   # Approximate as sum of density × thickness for each layer\n",
        "   ```\n",
        "\n",
        "5. **Custom visualization**: Create your own plot combining multiple profiles (e.g., temperature and density on the same axes with different scales)\n",
        "\n",
        "6. **Filter layers**: Extract and analyze only specific layers (e.g., surface layers, weak layers) based on hardness or other criteria\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### CAAML Reader Notes\n",
        "\n",
        "- **Version support**: Reader supports CAAML versions up to 6.0.5\n",
        "- **Namespace requirement**: Files must use a single, consistent CAAML namespace\n",
        "- **Missing data**: Missing numeric values become `None` in the SnowProfile object\n",
        "- **Category values**: Category values (like hand hardness) are converted to numeric mid-classes\n",
        "- **Data loss**: Some custom/user-defined data may not round-trip when reading and rewriting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "1. **`plot_full` single-Axes error**: \n",
        "   - **Problem**: `TypeError: 'Axes' object is not iterable` when only one subplot is created\n",
        "   - **Solution**: Use `plot_full_safe()` wrapper provided in this notebook, which uses `squeeze=False` and `axs.ravel()` to handle edge cases\n",
        "\n",
        "2. **`loc` attribute validation errors**:\n",
        "   - **Problem**: `ValueError: Unauthorized value for key loc`\n",
        "   - **Cause**: Some CAAML exporters use non-standard `loc` values like \"Surface\", \"Bottom\" instead of \"T\", \"B\"\n",
        "   - **Solution**: Use the `sanitize_caaml_loc()` helper function to normalize values before reading\n",
        "\n",
        "3. **Missing temperature profiles**:\n",
        "   - **Problem**: Code fails when trying to analyze temperature gradients\n",
        "   - **Solution**: Always check if profiles exist before accessing them: `if sp.temperature_profiles: ...`\n",
        "\n",
        "4. **Hand-hardness confusion**:\n",
        "   - **Note**: Hand-hardness values appear in the stratigraphy panel. The separate Hardness profile subplot requires actual `HardnessProfile` data (numeric hardness measurements), not hand-hardness categories. See the plot functions documentation for details.\n",
        "\n",
        "### Getting Help\n",
        "\n",
        "- Check the `snowprofile` package documentation for function names and signatures\n",
        "- Reference the official CAAML schema documentation\n",
        "- Use `help(snowprofile.io.read_caaml6_xml)` for function documentation\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
