{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Austfi/SNOWPACKforPatrollers/blob/main/SNOWPACKforPatrollers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f3164ae"
   },
   "source": [
    "# SNOWPACK Model Setup and Execution\n",
    "\n",
    "This notebook guides you through the process of setting up and running the SNOWPACK model. It includes steps for installing necessary libraries, compiling the SNOWPACK and MeteoIO code, configuring the model, fetching meteorological data from historical weather models, and running SNOWPACK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVNWofRBqYRU"
   },
   "source": [
    "# The following cells below set up SNOWPACK AND MeteoIO and the PATH structure to run it. They should not be edited. Pressing the play button below will run them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmAf9pWqC-Bc",
    "outputId": "2fd5098b-5d8f-47df-fe7e-b1fdd7d3a956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
      "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
      "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Waiting for headers] [Wai\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "\r0% [Waiting for headers] [5 InRelease 14.2 kB/129 kB 11%] [Waiting for headers]\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,855 kB]\n",
      "Fetched 5,833 kB in 2s (3,699 kB/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.9ubuntu3).\n",
      "liblapack-dev is already the newest version (3.10.0-2ubuntu1).\n",
      "numdiff is already the newest version (5.9.0-1).\n",
      "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
      "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n",
      "Requirement already satisfied: openmeteo-requests in /usr/local/lib/python3.12/dist-packages (1.7.4)\n",
      "Requirement already satisfied: requests-cache in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
      "Requirement already satisfied: retry-requests in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: niquests>=3.15.2 in /usr/local/lib/python3.12/dist-packages (from openmeteo-requests) (3.15.2)\n",
      "Requirement already satisfied: openmeteo-sdk>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from openmeteo-requests) (1.22.0)\n",
      "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (25.4.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (25.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (2.32.4)\n",
      "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (2.2.1)\n",
      "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from cattrs>=22.2->requests-cache) (4.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from niquests>=3.15.2->openmeteo-requests) (3.4.4)\n",
      "Requirement already satisfied: urllib3-future<3,>=2.13.903 in /usr/local/lib/python3.12/dist-packages (from niquests>=3.15.2->openmeteo-requests) (2.14.905)\n",
      "Requirement already satisfied: wassima<3,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from niquests>=3.15.2->openmeteo-requests) (2.0.2)\n",
      "Requirement already satisfied: h11<1.0.0,>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests) (0.16.0)\n",
      "Requirement already satisfied: jh2<6.0.0,>=5.0.3 in /usr/local/lib/python3.12/dist-packages (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests) (5.0.10)\n",
      "Requirement already satisfied: qh3<2.0.0,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests) (1.5.5)\n",
      "Requirement already satisfied: flatbuffers==25.9.23 in /usr/local/lib/python3.12/dist-packages (from openmeteo-sdk>=1.22.0->openmeteo-requests) (25.9.23)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->requests-cache) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->requests-cache) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "# @title Install environment updates\n",
    "!apt-get update\n",
    "!apt-get install -y build-essential cmake git liblapack-dev numdiff\n",
    "\n",
    "%pip install openmeteo-requests requests-cache retry-requests pandas numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from pathlib import Path\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import json\n",
    "from typing import Optional\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fast-install-snowpack"
   },
   "outputs": [],
   "source": [
    "# @title Install SNOWPACK via Binaries (Fast)\n",
    "# 1. Upgrade libstdc++6 to support GLIBCXX_3.4.32 (required by Snowpack 3.7.0)\n",
    "!add-apt-repository -y ppa:ubuntu-toolchain-r/test\n",
    "!apt-get update\n",
    "!apt-get install -y libstdc++6\n",
    "\n",
    "# 2. Download official compiled binaries (Snowpack bundle includes MeteoIO)\n",
    "!wget -O snowpack.deb https://gitlabext.wsl.ch/api/v4/projects/32/packages/generic/snowpack/3.7.0/Snowpack-3.7.0-x86_64.deb\n",
    "\n",
    "# 3. Install it\n",
    "!dpkg -i --force-overwrite snowpack.deb\n",
    "!apt-get install -f -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-snowpack-install"
   },
   "outputs": [],
   "source": [
    "# @title Verify SNOWPACK Installation\n",
    "import os\n",
    "!which snowpack\n",
    "!snowpack --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yvdowMMw8XL"
   },
   "source": [
    "# The above cells have set up SNOWPACK and made it ready to run. The below cells create the files, collect data, and run the snowpack model. This generates snowprofiles with no snow to start the model from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "6Fxry_54s13l",
    "outputId": "da3985d8-dbf1-4807-d213-fd1d29b332ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNOWPACK Configuration Files Generation\n",
      "==================================================\n",
      "Station: watrous_E_NTL (watrous)\n",
      "Location: 39.714380\u00b0N, -105.844750\u00b0W, 3596.6400000000003m\n",
      "Sno Directory: /content/input\n",
      "Ini Directory: /content/config\n",
      "==================================================\n",
      "\n",
      " Configuration files created:\n",
      "   .ini file: /content/config/watrous.ini\n",
      "   .sno files:\n",
      "     /content/input/keystone.sno\n",
      "     /content/input/keystone1.sno\n",
      "     /content/input/keystone2.sno\n",
      "     /content/input/keystone3.sno\n",
      "     /content/input/keystone4.sno\n",
      "\n",
      "Virtual slopes configured: 5\n",
      "   Slope 1: Flat (0\u00b0) -> keystone.sno\n",
      "   Slope 2: 38.0\u00b0 slope facing North -> keystone1.sno\n",
      "   Slope 3: 38.0\u00b0 slope facing East -> keystone2.sno\n",
      "   Slope 4: 38.0\u00b0 slope facing South -> keystone3.sno\n",
      "   Slope 5: 38.0\u00b0 slope facing West -> keystone4.sno\n",
      "\n",
      "SNOWPACK settings:\n",
      "   MEAS_TSS = false\n",
      "   ENFORCE_MEASURED_SNOW_HEIGHTS = false\n",
      "   NUMBER_SLOPES = 5\n",
      "\n",
      "\ud83c\udf89 SNOWPACK configuration generation complete!\n"
     ]
    }
   ],
   "source": [
    "#@title SNOWPACK Configuration Files Generation\n",
    "\"\"\"\n",
    "Generate .sno and .ini configuration files for SNOWPACK simulations\n",
    "\"\"\"\n",
    "\n",
    "#@markdown ## Station Configuration\n",
    "station_id = \"watrous\"  #@param {\"type\":\"string\"}\n",
    "station_name = \"watrous_E_NTL\"  #@param {\"type\":\"string\"}\n",
    "latitude = 39.71438  #@param {\"type\":\"number\"}\n",
    "longitude = -105.84475  #@param {\"type\":\"number\"}\n",
    "altitude = 11800  #@param {\"type\":\"integer\"}\n",
    "altitude_unit = \"feet\"  # @param [\"meters\", \"feet\"]\n",
    "timezone = -7  #@param {\"type\":\"number\"}\n",
    "profile_date = \"2024-11-01T00:00:00\"  #@param {\"type\":\"string\"}\n",
    "coord_sys = \"UTM\" #@param {\"type\":\"string\"}\n",
    "coord_param = \"13S\" #@param {\"type\":\"string\"}\n",
    "\n",
    "#@markdown ## Virtual Slopes Configuration\n",
    "num_slopes = 5  #@param {\"type\":\"number\", \"min\":1, \"max\":10}\n",
    "include_flat = True  #@param {\"type\":\"boolean\"}\n",
    "default_slope_angle = 38.0  #@param {\"type\":\"number\", \"min\":0, \"max\":90}\n",
    "\n",
    "#@markdown ## Slope Directions (degrees: 0=North, 90=East, 180=South, 270=West)\n",
    "north_slope = True  #@param {\"type\":\"boolean\"}\n",
    "east_slope = True  #@param {\"type\":\"boolean\"}\n",
    "south_slope = True  #@param {\"type\":\"boolean\"}\n",
    "west_slope = True  #@param {\"type\":\"boolean\"}\n",
    "custom_directions = \"\"  #@param {\"type\":\"string\"} {description:\"Comma-separated azimuth angles (e.g., 45,135,225,315)\"}\n",
    "\n",
    "#@markdown ## SNOWPACK Settings\n",
    "meas_tss = \"false\"  #@param [\"true\",\"false\"]\n",
    "enforce_measured_snow_heights = \"false\"  #@param [\"true\",\"false\"]\n",
    "write_profiles = \"true\"  #@param [\"true\",\"false\"]\n",
    "write_timeseries = \"false\"  #@param [\"true\",\"false\"]\n",
    "write_snowpack = \"false\"  #@param [\"true\",\"false\"]\n",
    "\n",
    "#@markdown ## Output Configuration\n",
    "sno_directory = \"/content/input\"  #@param {\"type\":\"string\"}\n",
    "ini_directory = \"/content/config\"  #@param {\"type\":\"string\"}\n",
    "generate_config_files = True  #@param {\"type\":\"boolean\"}\n",
    "\n",
    "# @markdown ### SNOWPACK Run End Date\n",
    "snowpack_end_date_input = \"2025-04-01\"  # @param {type:\"date\"}\n",
    "snowpack_end_date = f\"{snowpack_end_date_input}T00:00\"\n",
    "\n",
    "# For local testing - use current directory\n",
    "import os\n",
    "if not os.path.exists(\"/content\"):\n",
    "    sno_directory = \".\"\n",
    "    ini_directory = \".\"\n",
    "\n",
    "def generate_slopes(include_flat, north_slope, east_slope, south_slope, west_slope, custom_directions, default_slope_angle):\n",
    "    \"\"\"Generate list of virtual slopes based on user selections\"\"\"\n",
    "    slopes = []\n",
    "\n",
    "    # Add flat slope if requested\n",
    "    if include_flat:\n",
    "        slopes.append((0.0, 0.0))\n",
    "\n",
    "    # Add cardinal direction slopes\n",
    "    if north_slope:\n",
    "        slopes.append((default_slope_angle, 0.0))\n",
    "    if east_slope:\n",
    "        slopes.append((default_slope_angle, 90.0))\n",
    "    if south_slope:\n",
    "        slopes.append((default_slope_angle, 180.0))\n",
    "    if west_slope:\n",
    "        slopes.append((default_slope_angle, 270.0))\n",
    "\n",
    "    # Add custom directions\n",
    "    if custom_directions.strip():\n",
    "        try:\n",
    "            custom_angles = [float(x.strip()) for x in custom_directions.split(',')]\n",
    "            for angle in custom_angles:\n",
    "                if 0 <= angle <= 360:\n",
    "                    slopes.append((default_slope_angle, angle))\n",
    "        except ValueError:\n",
    "            print(\"Warning: Invalid custom directions format. Use comma-separated numbers.\")\n",
    "\n",
    "    return slopes\n",
    "\n",
    "def to_meters(value: float, unit: str) -> float:\n",
    "    \"\"\"Normalize altitude inputs so downstream code always works in meters.\"\"\"\n",
    "    unit = unit.lower()\n",
    "    if unit == \"meters\":\n",
    "        return float(value)\n",
    "    if unit == \"feet\":\n",
    "        return float(value) * 0.3048\n",
    "    raise ValueError(f\"Unsupported altitude unit: {unit}\")\n",
    "\n",
    "# Using variables from the configuration cell\n",
    "altitude_meters = to_meters(altitude, altitude_unit)\n",
    "\n",
    "def create_sno_content(station_id, station_name, longitude, latitude, altitude_meters, timezone, profile_date, slope_angle, slope_azimuth):\n",
    "    \"\"\"Create .sno file content for a single slope\"\"\"\n",
    "\n",
    "    content = f\"\"\"SMET 1.1 ASCII\n",
    "[HEADER]\n",
    "station_id       = {station_id}\n",
    "station_name     = {station_name}\n",
    "longitude        = {longitude}\n",
    "latitude         = {latitude}\n",
    "altitude         = {altitude_meters}\n",
    "nodata           = -999\n",
    "tz               = {timezone}\n",
    "source           = OpenMeteo\n",
    "prototype        = SNOWPACK\n",
    "ProfileDate      = {profile_date}\n",
    "HS_Last          = 0.0000\n",
    "SlopeAngle       = {slope_angle}\n",
    "SlopeAzi         = {slope_azimuth}\n",
    "nSoilLayerData   = 0\n",
    "nSnowLayerData   = 0\n",
    "SoilAlbedo       = 0.09\n",
    "BareSoil_z0      = 0.020\n",
    "CanopyHeight     = 0.00\n",
    "CanopyLeafAreaIndex = 0.00\n",
    "CanopyDirectThroughfall = 1.00\n",
    "ErosionLevel     = 0\n",
    "TimeCountDeltaHS = 0.000000\n",
    "WindScalingFactor = 1.00\n",
    "\n",
    "fields           = timestamp Layer_Thick  T  Vol_Frac_I  Vol_Frac_W  Vol_Frac_V  Vol_Frac_S Rho_S Conduc_S HeatCapac_S  rg  rb  dd  sp  mk mass_hoar ne CDot metamo\n",
    "[DATA]\n",
    "\"\"\"\n",
    "\n",
    "    return content\n",
    "\n",
    "def create_ini_content(station_id, filename, snowfiles, meas_tss, enforce_measured_snow_heights,\n",
    "                        coord_sys, coord_param, timezone, write_profiles, write_timeseries, write_snowpack):\n",
    "    \"\"\"Create .ini file content with multiple SNOWFILE entries\n",
    "\n",
    "    Args:\n",
    "        station_id: Station identifier\n",
    "        filename: SMET filename\n",
    "        snowfiles: List of .sno filenames\n",
    "        meas_tss: MEAS_TSS setting (\"true\" or \"false\")\n",
    "        enforce_measured_snow_heights: ENFORCE_MEASURED_SNOW_HEIGHTS setting (\"true\" or \"false\")\n",
    "        coord_sys: Coordinate system (e.g., \"UTM\")\n",
    "        coord_param: Coordinate parameter (e.g., \"13S\")\n",
    "        timezone: Timezone offset (e.g., -7)\n",
    "        write_profiles: PROF_WRITE setting (\"true\" or \"false\")\n",
    "        write_timeseries: TS_WRITE setting (\"true\" or \"false\")\n",
    "        write_snowpack: SNOW_WRITE setting (\"true\" or \"false\")\n",
    "\n",
    "    Returns:\n",
    "        String containing .ini file content\n",
    "    \"\"\"\n",
    "\n",
    "    content = f\"\"\"[General]\n",
    "BUFFER_SIZE = 370\n",
    "BUFF_BEFORE = 1.5\n",
    "\n",
    "[Input]\n",
    "COORDSYS = {coord_sys}\n",
    "COORDPARAM = {coord_param}\n",
    "TIME_ZONE = {timezone}\n",
    "\n",
    "METEO = SMET\n",
    "METEOPATH = ../input\n",
    "METEOFILE1 = {filename}\n",
    "\"\"\"\n",
    "\n",
    "    # Add SNOWFILE entries for each slope\n",
    "    for i, snowfile in enumerate(snowfiles, 1):\n",
    "        content += f\"SNOWFILE{i} = {snowfile}\\n\"\n",
    "\n",
    "    content += f\"\"\"\n",
    "[Output]\n",
    "COORDSYS = {coord_sys}\n",
    "COORDPARAM = {coord_param}\n",
    "TIME_ZONE = {timezone}\n",
    "METEOPATH = ./output\n",
    "EXPERIMENT = res\n",
    "SNOW_WRITE = {write_snowpack.lower()}\n",
    "\n",
    "TS_WRITE = {write_timeseries.lower()}\n",
    "TS_FORMAT = SMET\n",
    "TS_START = 0.0\n",
    "TS_DAYS_BETWEEN = 0.125\n",
    "PROF_WRITE = {write_profiles.lower()}\n",
    "PROF_FORMAT = PRO\n",
    "AGGREG_PRF = false\n",
    "PROF_START = 0.0\n",
    "PROF_DAYS_BETWEEN = 0.125\n",
    "\n",
    "[Snowpack]\n",
    "MEAS_TSS = {meas_tss.lower()}\n",
    "ENFORCE_MEASURED_SNOW_HEIGHTS = {enforce_measured_snow_heights.lower()}\n",
    "FORCING = ATMOS\n",
    "SW_MODE = INCOMING\n",
    "MEAS_INCOMING_LONGWAVE = false\n",
    "HEIGHT_OF_WIND_VALUE = 4.5\n",
    "HEIGHT_OF_METEO_VALUES = 4.5\n",
    "ATMOSPHERIC_STABILITY = MO_MICHLMAYR\n",
    "ROUGHNESS_LENGTH = 0.002\n",
    "CALCULATION_STEP_LENGTH = 15.0\n",
    "CHANGE_BC = false\n",
    "THRESH_CHANGE_BC = -1.0\n",
    "SNP_SOIL = false\n",
    "SOIL_FLUX = false\n",
    "GEO_HEAT = 0.06\n",
    "CANOPY = false\n",
    "\n",
    "[SnowpackAdvanced]\n",
    "FIXED_POSITIONS = 0.25 0.5 1.0 -0.25 -0.10\n",
    "SNOW_EROSION = TRUE\n",
    "WIND_SCALING_FACTOR = 1.0\n",
    "NUMBER_SLOPES = {len(snowfiles)}\n",
    "SNOW_REDISTRIBUTION = TRUE\n",
    "    THRESH_RAIN = 1.4\\n",
    "    T_CRAZY_MIN = 140\\n",
    "    T_CRAZY_MAX = 360\\n",
    "\n",
    "[Filters]\n",
    "ENABLE_METEO_FILTERS = true\n",
    "PSUM::filter1 = min\n",
    "PSUM::arg1::soft = true\n",
    "PSUM::arg1::min = 0.0\n",
    "TA::filter1 = min_max\n",
    "TA::arg1::min = 240\n",
    "TA::arg1::max = 320\n",
    "RH::filter1 = min_max\n",
    "RH::arg1::min = 0.01\n",
    "RH::arg1::max = 1.2\n",
    "RH::filter2 = min_max\n",
    "RH::arg2::soft = true\n",
    "RH::arg2::min = 0.05\n",
    "RH::arg2::max = 1.0\n",
    "ISWR::filter1 = min_max\n",
    "ISWR::arg1::min = -10\n",
    "ISWR::arg1::max = 1500\n",
    "ISWR::filter2 = min_max\n",
    "ISWR::arg2::soft = true\n",
    "ISWR::arg2::min = 0\n",
    "ISWR::arg2::max = 1500\n",
    "RSWR::filter1 = min_max\n",
    "RSWR::arg1::min = -10\n",
    "RSWR::arg1::max = 1500\n",
    "RSWR::filter2 = min_max\n",
    "RSWR::arg2::soft = true\n",
    "RSWR::arg2::min = 0\n",
    "RSWR::arg2::max = 1500\n",
    "ILWR::filter1 = min_max\n",
    "ILWR::arg1::min = 188\n",
    "ILWR::arg1::max = 600\n",
    "ILWR::filter2 = min_max\n",
    "ILWR::arg2::soft = true\n",
    "ILWR::arg2::min = 200\n",
    "ILWR::arg2::max = 400\n",
    "TSS::filter1 = min_max\n",
    "TSS::arg1::min = 200\n",
    "TSS::arg1::max = 320\n",
    "TSG::filter1 = min_max\n",
    "TSG::arg1::min = 200\n",
    "TSG::arg1::max = 320\n",
    "HS::filter1 = min\n",
    "HS::arg1::soft = true\n",
    "HS::arg1::min = 0.0\n",
    "HS::filter2 = rate\n",
    "HS::arg2::max = 5.55e-5\n",
    "VW::filter1 = min_max\n",
    "VW::arg1::min = -2\n",
    "VW::arg1::max = 70\n",
    "VW::filter2 = min_max\n",
    "VW::arg2::soft = true\n",
    "VW::arg2::min = 0.0\n",
    "VW::arg2::max = 50.0\n",
    "\n",
    "[Interpolations1D]\n",
    "MAX_GAP_SIZE = 86400\n",
    "PSUM::resample1 = accumulate\n",
    "PSUM::ACCUMULATE::PERIOD = 900\n",
    "HS::resample1 = linear\n",
    "HS::LINEAR::MAX_GAP_SIZE = 43200\n",
    "VW::resample1 = nearest\n",
    "VW::NEAREST::EXTRAPOLATE = true\n",
    "DW::resample1 = nearest\n",
    "DW::NEAREST::EXTRAPOLATE = true\n",
    "\n",
    "[Generators]\n",
    "ILWR::generator1 = AllSky_LW\n",
    "ILWR::arg1::type = Carmona\n",
    "ILWR::arg1::shade_from_dem = FALSE\n",
    "ILWR::arg1::use_rswr = FALSE\n",
    "ILWR::generator2 = ClearSky_LW\n",
    "ILWR::arg2::type = Dilley\n",
    "\"\"\"\n",
    "\n",
    "    return content\n",
    "\n",
    "def get_slope_filename(angle, azimuth, slope_index, include_flat):\n",
    "    \"\"\"Get filename for slope naming convention.\n",
    "\n",
    "    Naming rules:\n",
    "    - Flat slope (angle == 0.0): Returns 'keystone' (no number)\n",
    "    - Non-flat slopes: Returns 'keystone1', 'keystone2', etc.\n",
    "    - Numbering depends on whether flat slope is included:\n",
    "      * If flat included: non-flat slopes start from index 1\n",
    "      * If flat not included: all slopes start from index 1\n",
    "\n",
    "    Args:\n",
    "        angle: Slope angle in degrees (0.0 for flat)\n",
    "        azimuth: Slope azimuth in degrees\n",
    "        slope_index: Index of slope in the slopes list\n",
    "        include_flat: Whether flat slope is included in the list\n",
    "\n",
    "    Returns:\n",
    "        Filename base (without .sno extension)\n",
    "    \"\"\"\n",
    "    if angle == 0.0:\n",
    "        return \"keystone\"  # Flat slope gets no number\n",
    "    else:\n",
    "        # For numbered slopes, determine the number based on position\n",
    "        if include_flat:\n",
    "            # If flat is included, non-flat slopes start from index 1\n",
    "            return f\"keystone{slope_index}\"\n",
    "        else:\n",
    "            # If no flat, start numbering from 1\n",
    "            return f\"keystone{slope_index + 1}\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "\n",
    "    print(\"SNOWPACK Configuration Files Generation\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Station: {station_name} ({station_id})\")\n",
    "    print(f\"Location: {latitude:.6f}\u00b0N, {longitude:.6f}\u00b0W, {altitude_meters}m\")\n",
    "    print(f\"Sno Directory: {sno_directory}\")\n",
    "    print(f\"Ini Directory: {ini_directory}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if not generate_config_files:\n",
    "        print(\"Configuration generation disabled. Set 'generate_config_files' to True to generate files.\")\n",
    "        return\n",
    "\n",
    "    # Validate profile_date format\n",
    "    try:\n",
    "        from datetime import datetime\n",
    "        datetime.strptime(profile_date, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    except ValueError:\n",
    "        print(f\"Warning: profile_date format may be incorrect. Expected format: YYYY-MM-DDTHH:MM:SS\")\n",
    "        print(f\"  Current value: {profile_date}\")\n",
    "\n",
    "    # Validate directories\n",
    "    try:\n",
    "        os.makedirs(sno_directory, exist_ok=True)\n",
    "        os.makedirs(ini_directory, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directories: {e}\")\n",
    "        return\n",
    "\n",
    "    # Generate slopes\n",
    "    slopes = generate_slopes(include_flat, north_slope, east_slope, south_slope, west_slope, custom_directions, default_slope_angle)\n",
    "\n",
    "    # Limit to requested number of slopes\n",
    "    if len(slopes) > num_slopes:\n",
    "        slopes = slopes[:num_slopes]\n",
    "        print(f\"Warning: Limited to {num_slopes} slopes as requested\")\n",
    "\n",
    "    # Create multiple .sno files and collect snowfile names\n",
    "    snowfiles = []\n",
    "    sno_files_created = []\n",
    "\n",
    "    for i, (angle, azimuth) in enumerate(slopes):\n",
    "        # Get filename based on new naming convention\n",
    "        sno_filename = get_slope_filename(angle, azimuth, i, include_flat) + \".sno\"\n",
    "        snowfiles.append(sno_filename)\n",
    "\n",
    "        # Create .sno content for this slope\n",
    "        sno_content = create_sno_content(station_id, station_name, longitude, latitude, altitude_meters, timezone, profile_date, angle, azimuth)\n",
    "\n",
    "        # Write .sno file to input directory\n",
    "        sno_filepath = os.path.join(sno_directory, sno_filename)\n",
    "        try:\n",
    "            with open(sno_filepath, \"w\") as f:\n",
    "                f.write(sno_content)\n",
    "            sno_files_created.append(sno_filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing {sno_filepath}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Create .ini content with multiple SNOWFILE entries\n",
    "    ini_content = create_ini_content(\n",
    "        station_id,\n",
    "        f\"{station_id}.smet\",\n",
    "        snowfiles,\n",
    "        meas_tss,\n",
    "        enforce_measured_snow_heights,\n",
    "        coord_sys,\n",
    "        coord_param,\n",
    "        timezone,\n",
    "        write_profiles,\n",
    "        write_timeseries,\n",
    "        write_snowpack\n",
    "    )\n",
    "\n",
    "    # Write .ini file to keystone directory\n",
    "    ini_filename = os.path.join(ini_directory, f\"{station_id}.ini\")\n",
    "    try:\n",
    "        with open(ini_filename, \"w\") as f:\n",
    "            f.write(ini_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing {ini_filename}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Display results\n",
    "    print(f\"\\n Configuration files created:\")\n",
    "    print(f\"   .ini file: {ini_filename}\")\n",
    "    print(f\"   .sno files:\")\n",
    "    for sno_file in sno_files_created:\n",
    "        print(f\"     {sno_file}\")\n",
    "\n",
    "    print(f\"\\nVirtual slopes configured: {len(slopes)}\")\n",
    "    for i, (angle, azimuth) in enumerate(slopes):\n",
    "        sno_filename = get_slope_filename(angle, azimuth, i, include_flat)\n",
    "        if angle == 0.0:\n",
    "            print(f\"   Slope {i+1}: Flat (0\u00b0) -> {sno_filename}.sno\")\n",
    "        else:\n",
    "            direction = \"\"\n",
    "            if azimuth == 0.0:\n",
    "                direction = \"North\"\n",
    "            elif azimuth == 90.0:\n",
    "                direction = \"East\"\n",
    "            elif azimuth == 180.0:\n",
    "                direction = \"South\"\n",
    "            elif azimuth == 270.0:\n",
    "                direction = \"West\"\n",
    "            else:\n",
    "                direction = f\"{azimuth}\u00b0\"\n",
    "            print(f\"   Slope {i+1}: {angle}\u00b0 slope facing {direction} -> {sno_filename}.sno\")\n",
    "\n",
    "    print(f\"\\nSNOWPACK settings:\")\n",
    "    print(f\"   MEAS_TSS = {meas_tss}\")\n",
    "    print(f\"   ENFORCE_MEASURED_SNOW_HEIGHTS = {enforce_measured_snow_heights}\")\n",
    "    print(f\"   NUMBER_SLOPES = {len(slopes)}\")\n",
    "\n",
    "    print(\"\\n\ud83c\udf89 SNOWPACK configuration generation complete!\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "1tDfNJYn15FI",
    "outputId": "d26dafba-fe68-4b0b-bce1-d5c5ddcfa814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMET Generation Parameters\n",
      "==================================================\n",
      "Location: 39.71438, -105.84475\n",
      "Altitude input: 11800 feet (3596.64 m used for calculations)\n",
      "Station: watrous_E_NTL\n",
      "Period: 2024-11-01 to 2025-04-30\n",
      "Model: ifs\n",
      "Generate: True\n",
      "Open-Meteo elevation: 3596.64 m (selected altitude)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# @title SMET Handling, API Setup, and Parameters\n",
    "\n",
    "# @markdown ### Location Settings are used from above.\n",
    "# Pulling from the configuration cell\n",
    "# latitude = 39.56858687967004  # @param {type:\"number\"}\n",
    "# longitude = -105.91900397453021  # @param {type:\"number\"}\n",
    "# altitude_input = 3614  # @param {type:\"number\"}\n",
    "# altitude_unit = \"meters\"  # @param [\"meters\", \"feet\"]\n",
    "\n",
    "# @markdown ### Station Information is used from above.\n",
    "# Pulling from the configuration cell\n",
    "# station_name = \"keystone_model\"  # @param {type:\"string\"}\n",
    "\n",
    "# @markdown ### Time Period\n",
    "start_date = \"2024-11-01\"  # @param {type:\"date\"}\n",
    "end_date = \"2025-04-30\"    # @param {type:\"date\"}\n",
    "\n",
    "# @markdown ### Weather Model\n",
    "model_selection = \"ifs\"  # @param [\"nbm\", \"ifs\", \"gfs\", \"hrrr\"]\n",
    "\n",
    "# @markdown ### HS (Snow Depth) Source\n",
    "hs_source = \"model\"  # @param [\"model\", \"snodas\"]\n",
    "\n",
    "# @markdown ### Open-Meteo Elevation\n",
    "openmeteo_elevation_mode = \"use_selected_altitude\"  # @param [\"use_model_elevation\", \"use_selected_altitude\"]\n",
    "\n",
    "# @markdown ### SMET Generation\n",
    "generate_files = True  # @param {type:\"boolean\"}\n",
    "\n",
    "# --- Helper functions ----------------------------------------------------\n",
    "\n",
    "# Imports for SNODAS\n",
    "import struct\n",
    "import tarfile\n",
    "import gzip\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "from io import BytesIO\n",
    "import datetime\n",
    "\n",
    "def get_snodas_snow_depth(lat, lon, date_str, cache_dir=\"snodas_cache\", debug=False):\n",
    "    \"\"\"\n",
    "    Download and extract SNODAS snow depth from NSIDC.\n",
    "    \n",
    "    SNODAS Units:\n",
    "    - Raw data: millimeters (mm) stored as integer (snow_depth_raw / 1000.0)\n",
    "    - Returns: meters (m) as float\n",
    "    \n",
    "    This is different from Open-Meteo which returns centimeters (cm).\n",
    "    \"\"\"\n",
    "    SNODAS_NODATA = -9999\n",
    "    \n",
    "    # Grid configurations (detected from file size)\n",
    "    GRID_CONFIGS = {\n",
    "        'old': {'XMIN': -124.73375000000000, 'YMAX': 52.87458333333333, \n",
    "                'XMAX': -66.94208333333333, 'YMIN': 24.94958333333333,\n",
    "                'NCOLS': 6935, 'NROWS': 3351, 'name': 'Pre-Oct-2013'},\n",
    "        'new': {'XMIN': -124.73333333333333, 'YMAX': 52.87500000000000,\n",
    "                'XMAX': -66.94166666666667, 'YMIN': 24.95000000000000,\n",
    "                'NCOLS': 3353, 'NROWS': 3353, 'name': 'Post-Oct-2013'}\n",
    "    }\n",
    "    \n",
    "    # Check location bounds\n",
    "    if lat < 24.95 or lat > 52.88 or lon < -124.74 or lon > -66.94:\n",
    "        return None\n",
    "    \n",
    "    # Construct URL\n",
    "    tar_filename = f\"SNODAS_{date_str}.tar\"\n",
    "    data_base = \"https://noaadata.apps.nsidc.org/NOAA/G02158/masked\"\n",
    "    year = date_str[:4]\n",
    "    month = date_str[4:6]\n",
    "    month_names = [\"01_Jan\", \"02_Feb\", \"03_Mar\", \"04_Apr\", \"05_May\", \"06_Jun\",\n",
    "                   \"07_Jul\", \"08_Aug\", \"09_Sep\", \"10_Oct\", \"11_Nov\", \"12_Dec\"]\n",
    "    month_dir = month_names[int(month) - 1]\n",
    "    data_url = f\"{data_base}/{year}/{month_dir}/{tar_filename}\"\n",
    "    \n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    cache_path = os.path.join(cache_dir, tar_filename)\n",
    "    \n",
    "    try:\n",
    "        # Download or use cache\n",
    "        if os.path.exists(cache_path):\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                tar_data = BytesIO(f.read())\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f\"  Downloading {date_str}...\")\n",
    "            # Set a user-agent to avoid potential 403s\n",
    "            req = urllib.request.Request(\n",
    "                data_url, \n",
    "                headers={'User-Agent': 'Mozilla/5.0'}\n",
    "            )\n",
    "            with urllib.request.urlopen(req, timeout=60) as response:\n",
    "                tar_data = BytesIO(response.read())\n",
    "                with open(cache_path, 'wb') as f:\n",
    "                    f.write(tar_data.getvalue())\n",
    "            tar_data.seek(0)\n",
    "        \n",
    "        # Extract and decompress\n",
    "        with tarfile.open(fileobj=tar_data, mode='r') as tar:\n",
    "            # Look for the .dat.gz file with the snow depth code (1036)\n",
    "            snow_depth_gz_file = None\n",
    "            for member in tar.getmembers():\n",
    "                if '1036' in member.name and member.name.endswith('.dat.gz'):\n",
    "                    snow_depth_gz_file = tar.extractfile(member)\n",
    "                    break\n",
    "            \n",
    "            if snow_depth_gz_file is None:\n",
    "                if debug: print(\"  Could not find snow depth file (1036) in tar archive\")\n",
    "                return None\n",
    "        \n",
    "            with gzip.open(snow_depth_gz_file, 'rb') as gz_file:\n",
    "                data = gz_file.read()\n",
    "        \n",
    "        # Detect grid from file size\n",
    "        num_values = len(data) // 2\n",
    "        grid_config = None\n",
    "        for config in GRID_CONFIGS.values():\n",
    "            if num_values == config['NCOLS'] * config['NROWS']:\n",
    "                grid_config = config\n",
    "                break\n",
    "        \n",
    "        if grid_config is None:\n",
    "            if debug: print(f\"  Could not detect grid configuration for size {len(data)}\")\n",
    "            return None\n",
    "        \n",
    "        # Parse binary data\n",
    "        SNODAS_NCOLS = grid_config['NCOLS']\n",
    "        SNODAS_NROWS = grid_config['NROWS']\n",
    "        values = struct.unpack(f\">{SNODAS_NCOLS * SNODAS_NROWS}h\", data)\n",
    "        snow_depth_array = np.array(values).reshape((SNODAS_NROWS, SNODAS_NCOLS))\n",
    "        \n",
    "        # Calculate grid coordinates\n",
    "        SNODAS_XMIN = grid_config['XMIN']\n",
    "        SNODAS_YMAX = grid_config['YMAX']\n",
    "        SNODAS_CELLSIZE_X = (grid_config['XMAX'] - SNODAS_XMIN) / SNODAS_NCOLS\n",
    "        SNODAS_CELLSIZE_Y = (SNODAS_YMAX - grid_config['YMIN']) / SNODAS_NROWS\n",
    "        \n",
    "        col = int((lon - SNODAS_XMIN) / SNODAS_CELLSIZE_X)\n",
    "        row = int((SNODAS_YMAX - lat) / SNODAS_CELLSIZE_Y)\n",
    "        \n",
    "        col = max(0, min(SNODAS_NCOLS - 1, col))\n",
    "        row = max(0, min(SNODAS_NROWS - 1, row))\n",
    "        \n",
    "        # Extract value\n",
    "        snow_depth_raw = snow_depth_array[row, col]\n",
    "        if snow_depth_raw == SNODAS_NODATA or snow_depth_raw < 0:\n",
    "            return None\n",
    "        \n",
    "        snow_depth_m = snow_depth_raw / 1000.0\n",
    "        return snow_depth_m if snow_depth_m >= 0.0 else 0.0\n",
    "            \n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"  Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def resolve_openmeteo_elevation(mode: str, station_alt_m: float) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Decide which elevation to send to the Open-Meteo API.\n",
    "    - use_model_elevation     -> None (API uses its DEM; statistical downscaling stays enabled)\n",
    "    - use_selected_altitude   -> the altitude value converted to meters above\n",
    "    \"\"\"\n",
    "    mode = mode.lower()\n",
    "    if mode == \"use_model_elevation\":\n",
    "        return None\n",
    "    if mode == \"use_selected_altitude\":\n",
    "        return float(station_alt_m)\n",
    "    raise ValueError(f\"Unknown elevation mode: {mode}\")\n",
    "\n",
    "\n",
    "def create_smet_from_weather_data(weather_df: pd.DataFrame,\n",
    "                                  output_path: str,\n",
    "                                  station_id: str,\n",
    "                                  station_name: str,\n",
    "                                  latitude: float,\n",
    "                                  longitude: float,\n",
    "                                  altitude_meters: float,\n",
    "                                  timezone: float = -7) -> None:\n",
    "    \"\"\"\n",
    "    Create a SMET file from a weather DataFrame and write it to disk.\n",
    "\n",
    "    Args:\n",
    "        weather_df: DataFrame containing weather data with timestamp column\n",
    "        output_path: Path where SMET file will be written\n",
    "        station_id: Station identifier\n",
    "        station_name: Station name\n",
    "        latitude: Latitude in degrees\n",
    "        longitude: Longitude in degrees\n",
    "        altitude_meters: Altitude in meters\n",
    "        timezone: Timezone offset (default: -7 for Mountain Time)\n",
    "    \"\"\"\n",
    "    if \"timestamp\" in weather_df.columns:\n",
    "        weather_df = weather_df.copy()\n",
    "        weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    else:\n",
    "        weather_df = weather_df.copy()\n",
    "        weather_df.reset_index(inplace=True)\n",
    "        weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "\n",
    "    fields = [\"timestamp\", \"TA\", \"RH\", \"TSG\", \"VW\", \"DW\", \"ISWR\", \"PSUM\"]\n",
    "    if \"HS\" in weather_df.columns:\n",
    "        fields.append(\"HS\")\n",
    "\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"SMET 1.1 ASCII\\n\")\n",
    "        f.write(\"[HEADER]\\n\")\n",
    "        f.write(f\"station_id = {station_id}\\n\")\n",
    "        f.write(f\"station_name = {station_name}\\n\")\n",
    "        f.write(f\"latitude = {latitude:.10f}\\n\")\n",
    "        f.write(f\"longitude = {longitude:.10f}\\n\")\n",
    "        f.write(f\"altitude = {altitude_meters}\\n\")\n",
    "        f.write(\"nodata = -777\\n\")\n",
    "        f.write(f\"Tz = {timezone}\\n\")\n",
    "        fields_str = \"\\t\".join(fields)\n",
    "        f.write(f\"fields = {fields_str}\\n\")\n",
    "\n",
    "        field_count = len(fields)\n",
    "        units_offset = [\"0\"] * field_count\n",
    "        units_multiplier = [\"1\"] * field_count\n",
    "        f.write(f\"units_offset     = {' '.join(units_offset)}\\n\")\n",
    "        f.write(f\"units_multiplier = {' '.join(units_multiplier)}\\n\")\n",
    "\n",
    "        f.write(\"[DATA]\\n\")\n",
    "        for _, row in weather_df.iterrows():\n",
    "            values = []\n",
    "            for field in fields:\n",
    "                if field == \"timestamp\":\n",
    "                    values.append(row[field].strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "                else:\n",
    "                    val = row.get(field, -777)\n",
    "                    if pd.isna(val):\n",
    "                        val = -777\n",
    "                    values.append(f\"{val:.2f}\")\n",
    "            f.write(\"\\t\".join(values) + \"\\n\")\n",
    "\n",
    "\n",
    "def fetch_openmeteo_historical(lat: float,\n",
    "                               lon: float,\n",
    "                               start_date: str,\n",
    "                               end_date: str,\n",
    "                               model: str = \"gfs_global\",\n",
    "                               elevation: Optional[float] = None) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fetch historical forecast data from the Open-Meteo API.\n",
    "    \"\"\"\n",
    "    cache_session = requests_cache.CachedSession(\".cache\", expire_after=3600)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    url = \"https://historical-forecast-api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"relative_humidity_2m\",\n",
    "            \"wind_speed_10m\",\n",
    "            \"wind_direction_10m\",\n",
    "            \"snow_depth\",\n",
    "            \"direct_radiation\",\n",
    "            \"precipitation\",\n",
    "        ],\n",
    "        \"models\": model,\n",
    "        \"wind_speed_unit\": \"ms\",\n",
    "    }\n",
    "\n",
    "    if elevation is not None:\n",
    "        params[\"elevation\"] = elevation\n",
    "\n",
    "    print(f\"Fetching {model} data for {lat}, {lon} from {start_date} to {end_date}\")\n",
    "    if \"elevation\" in params:\n",
    "        print(f\"Open-Meteo elevation parameter: {params['elevation']} (m)\")\n",
    "\n",
    "    try:\n",
    "        responses = openmeteo.weather_api(url, params=params)\n",
    "        response = responses[0]\n",
    "\n",
    "        print(f\"Coordinates: {response.Latitude()}\u00b0N {response.Longitude()}\u00b0E\")\n",
    "        print(f\"Elevation: {response.Elevation()} m asl\")\n",
    "\n",
    "        hourly = response.Hourly()\n",
    "        hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "        hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "        hourly_wind_speed_10m = hourly.Variables(2).ValuesAsNumpy()\n",
    "        hourly_wind_direction_10m = hourly.Variables(3).ValuesAsNumpy()\n",
    "        hourly_snow_depth = hourly.Variables(4).ValuesAsNumpy()\n",
    "        hourly_direct_radiation = hourly.Variables(5).ValuesAsNumpy()\n",
    "        hourly_precipitation = hourly.Variables(6).ValuesAsNumpy()\n",
    "\n",
    "        time_index = pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"timestamp\": time_index,\n",
    "                \"TA\": hourly_temperature_2m + 273.15,   # Convert to Kelvin\n",
    "                \"RH\": hourly_relative_humidity_2m / 100.0,\n",
    "                \"VW\": hourly_wind_speed_10m,\n",
    "                \"DW\": hourly_wind_direction_10m,\n",
    "                \"HS\": hourly_snow_depth,\n",
    "                \"ISWR\": hourly_direct_radiation,\n",
    "                \"PSUM\": hourly_precipitation,\n",
    "            }\n",
    "        )\n",
    "        # TSG (ground temperature) is not available from Open-Meteo API\n",
    "        # Using assumed value of 273.15 K (0\u00b0C) as a reasonable default\n",
    "        # SNOWPACK will calculate actual ground temperature during simulation\n",
    "        df[\"TSG\"] = 273.15\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        print(f\"Fetched {len(df)} records\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- Derived values / summary -------------------------------------------\n",
    "\n",
    "# Validate dates\n",
    "try:\n",
    "    from datetime import datetime\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    if start_dt >= end_dt:\n",
    "        raise ValueError(f\"start_date ({start_date}) must be before end_date ({end_date})\")\n",
    "except ValueError as e:\n",
    "    print(f\"Date validation error: {e}\")\n",
    "    print(\"Please check your date inputs and try again.\")\n",
    "    raise\n",
    "\n",
    "# Validate that altitude_meters is available (from configuration cell)\n",
    "try:\n",
    "    altitude_meters\n",
    "except NameError:\n",
    "    print(\"Error: altitude_meters not found. Please run the configuration cell first.\")\n",
    "    raise\n",
    "\n",
    "# altitude_meters = altitude # Commented out direct assignment\n",
    "openmeteo_elevation = resolve_openmeteo_elevation(openmeteo_elevation_mode, altitude_meters)\n",
    "\n",
    "print(\"SMET Generation Parameters\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Location: {latitude}, {longitude}\")\n",
    "print(f\"Altitude input: {altitude} {altitude_unit} ({altitude_meters:.2f} m used for calculations)\")\n",
    "# print(f\"Altitude: {altitude_meters:.2f} m\")\n",
    "print(f\"Station: {station_name}\")\n",
    "print(f\"Period: {start_date} to {end_date}\")\n",
    "print(f\"Model: {model_selection}\")\n",
    "print(f\"Generate: {generate_files}\")\n",
    "if openmeteo_elevation is None:\n",
    "    print(\"Open-Meteo elevation: model elevation (automatic downscaling)\")\n",
    "else:\n",
    "    print(f\"Open-Meteo elevation: {openmeteo_elevation:.2f} m (selected altitude)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "P_qk-irE3klw",
    "outputId": "5130bc3e-2955-4b27-99ee-f9a5a2cef4c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SMET generation...\n",
      "Processing 1 model(s): ifs\n",
      "==================================================\n",
      "\n",
      "Processing ifs...\n",
      "Fetching ecmwf_ifs data for 39.71438, -105.84475 from 2024-11-01 to 2025-04-30\n",
      "Open-Meteo elevation parameter: 3596.6400000000003 (m)\n",
      "Coordinates: 39.68365478515625\u00b0N -105.875\u00b0E\n",
      "Elevation: 3596.639892578125 m asl\n",
      "Fetched 4344 records\n",
      "SMET file created: /content/input/watrous.smet\n",
      "Records: 4344\n",
      "Period: 2024-11-01 00:00:00+00:00 to 2025-04-30 23:00:00+00:00\n",
      "\n",
      "Successfully generated 1 SMET files:\n",
      "  /content/input/watrous.smet\n",
      "\n",
      "Files saved to: /content/input\n"
     ]
    }
   ],
   "source": [
    "# @title Generate SMET Files\n",
    "# @markdown Run this cell to generate SMET files with the parameters above\n",
    "\n",
    "# Hardcoded output path\n",
    "# output_directory = \"/content/input\" # Commented out hardcoded path\n",
    "\n",
    "# Use sno_directory from the configuration cell\n",
    "output_directory = sno_directory  # sno directory is input folder\n",
    "\n",
    "# Model mapping\n",
    "model_mapping = {\n",
    "    \"nbm\": \"ncep_nbm_conus\",\n",
    "    \"ifs\": \"ecmwf_ifs\",\n",
    "    \"gfs\": \"gfs_global\",\n",
    "    \"hrrr\": \"gfs_hrrr\"\n",
    "}\n",
    "\n",
    "\n",
    "if generate_files:\n",
    "    print(\"Starting SMET generation...\")\n",
    "\n",
    "    # Parse model selection\n",
    "    selected_models = [model_selection]\n",
    "\n",
    "    # Validate and map models\n",
    "    valid_models = ['nbm', 'ifs', 'gfs', 'hrrr']\n",
    "    selected_models = [model for model in selected_models if model in valid_models]\n",
    "\n",
    "    if not selected_models:\n",
    "        print(\"No valid models selected!\")\n",
    "        print(f\"Available models: {', '.join(valid_models)}\")\n",
    "    else:\n",
    "        print(f\"Processing {len(selected_models)} model(s): {', '.join(selected_models)}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        successful_files = []\n",
    "\n",
    "        for model in selected_models:\n",
    "            print(f\"\\nProcessing {model}...\")\n",
    "\n",
    "            # Map to Open-Meteo model name\n",
    "            openmeteo_model = model_mapping[model]\n",
    "\n",
    "            # Fetch data\n",
    "            df = fetch_openmeteo_historical(\n",
    "                lat=latitude,\n",
    "                lon=longitude,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                model=openmeteo_model,\n",
    "                elevation=openmeteo_elevation\n",
    "            )\n",
    "\n",
    "            if df is None or df.empty:\n",
    "                print(f\"Failed to fetch data for {model}\")\n",
    "                continue\n",
    "\n",
    "            # SNODAS Integration\n",
    "            if 'hs_source' in locals() and hs_source == \"snodas\":\n",
    "                print(f\"  Fetching SNODAS snow depth for {len(df)} records...\")\n",
    "                # Determine unique dates to fetch\n",
    "                df['date_key'] = df['timestamp'].dt.strftime(\"%Y%m%d\")\n",
    "                unique_dates = df['date_key'].unique()\n",
    "                snodas_cache = {}\n",
    "                \n",
    "                print(f\"  Retrieving SNODAS data for {len(unique_dates)} days...\")\n",
    "                for date_str in unique_dates:\n",
    "                    try:\n",
    "                        depth = get_snodas_snow_depth(latitude, longitude, date_str)\n",
    "                        if depth is not None:\n",
    "                            snodas_cache[date_str] = depth\n",
    "                    except Exception as e:\n",
    "                        print(f\"    Warning: SNODAS fetch failed for {date_str}: {e}\")\n",
    "                \n",
    "                # Map back to hourly data\n",
    "                if snodas_cache:\n",
    "                    # Create mapping series\n",
    "                    snodas_series = df['date_key'].map(snodas_cache)\n",
    "                    \n",
    "                    # Count valid mapping\n",
    "                    valid_count = snodas_series.count()\n",
    "                    if valid_count > 0:\n",
    "                        df['HS'] = snodas_series\n",
    "                        # Fill missing with 0 or keep original? Using 0 if missing for now but warn\n",
    "                        # Actually, if we want to fallback to model, we should only overwrite where valid\n",
    "                        # BUT df['HS'] might not exist yet if model didn't provide it?\n",
    "                        # OpenMeteo usually provides 'snow_depth' in meters if requested? \n",
    "                        # Wait, create_smet_from_weather_data looks for 'HS'. \n",
    "                        \n",
    "                        print(f\"  \u2713 Applied SNODAS snow depth to {valid_count} records\")\n",
    "                    else:\n",
    "                        print(\"  \u26a0 No valid SNODAS data mapped\")\n",
    "                else:\n",
    "                    print(\"  \u26a0 No SNODAS data retrieved\")\n",
    "            \n",
    "            # Create output filename with simplified naming\n",
    "            output_file = os.path.join(output_directory, f\"{station_id}.smet\")\n",
    "            # could add in _{model} if wanted to specify\n",
    "\n",
    "            try:\n",
    "                # Generate SMET file\n",
    "                create_smet_from_weather_data(\n",
    "                    weather_df=df,\n",
    "                    output_path=output_file,\n",
    "                    station_id=f\"{station_id}_{model}\",\n",
    "                    station_name=f\"{station_name}_{model}\",\n",
    "                    latitude=latitude,\n",
    "                    longitude=longitude,\n",
    "                    altitude_meters=altitude_meters,\n",
    "                    timezone=timezone\n",
    "                )\n",
    "\n",
    "                print(f\"SMET file created: {output_file}\")\n",
    "                print(f\"Records: {len(df)}\")\n",
    "                print(f\"Period: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "\n",
    "                successful_files.append(output_file)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating SMET for {model}: {e}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"\\nSuccessfully generated {len(successful_files)} SMET files:\")\n",
    "        for file in successful_files:\n",
    "            print(f\"  {file}\")\n",
    "\n",
    "        if successful_files:\n",
    "            print(f\"\\nFiles saved to: {output_directory}\")\n",
    "else:\n",
    "    print(\"Generation disabled. Set 'generate_files' to True to generate SMET files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtR-OPRA43OO"
   },
   "outputs": [],
   "source": [
    "# @title Run this cell to run SNOWPACK\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Construct the path to the .ini file using variables from the configuration cell\n",
    "ini_filepath = os.path.join(ini_directory, f\"{station_id}.ini\")\n",
    "\n",
    "# Find the snowpack executable path dynamically\n",
    "try:\n",
    "    result = subprocess.run([\"which\", \"snowpack\"], capture_output=True, text=True, check=True)\n",
    "    snowpack_executable_path = result.stdout.strip()\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    snowpack_executable_path = \"snowpack\"  # Fallback to PATH lookup\n",
    "\n",
    "# Verify .ini file exists\n",
    "if not os.path.exists(ini_filepath):\n",
    "    raise FileNotFoundError(f\"Configuration file not found: {ini_filepath}\")\n",
    "\n",
    "# Run SNOWPACK with enhanced error reporting\n",
    "try:\n",
    "    print(f\"Running SNOWPACK with config: {ini_filepath}\")\n",
    "    result = subprocess.run(\n",
    "        [snowpack_executable_path, \"-c\", ini_filepath, \"-e\", snowpack_end_date],\n",
    "        cwd=ini_directory,\n",
    "        check=True,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    # If successful, print stdout\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"\\nError running SNOWPACK (exit code {e.returncode})\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"SNOWPACK STDERR:\")\n",
    "    print(e.stderr)\n",
    "    print(\"=\"*40)\n",
    "    print(\"SNOWPACK STDOUT:\")\n",
    "    print(e.stdout)\n",
    "    raise\n",
    "except FileNotFoundError:\n",
    "    print(f\"SNOWPACK executable not found: {snowpack_executable_path}\")\n",
    "    print(\"Please ensure SNOWPACK is compiled and in PATH\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "collapsed": true,
    "id": "2wQuuL4KEJO5",
    "outputId": "0373e4a5-7472-49ad-a943-2466bf22a9cb"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_b8602e68-72cc-4adc-9d7c-c029576ddf78\", \"snowpack_profiles.zip\", 232577340)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ---\n",
       "    10 SNOWPACK profile files have been downloaded as **`snowpack_profiles.zip`**.\n",
       "\n",
       "    Next Step \u2014 View in niViz\n",
       "    1. Go to https://run.niviz.org\n",
       "    2. Click \"File\" \u2192 \"Open Profile\" or drag any of the downloaded files into the screen\n",
       "    3. Select any of the downloaded files:\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`ksp_model_ifs4_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`ksp_model_ifs1_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs3_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`ksp_model_ifs3_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs2_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`ksp_model_ifs2_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`ksp_model_ifs_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs1_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs4_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Download .pro files and Open niViz\n",
    "# @markdown # 5 files will be download.\n",
    "# @markdown # 1 = N, 2=E, 3=S, 4=W,\n",
    "import glob, shutil, os\n",
    "from IPython.display import FileLink, Markdown\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Determine temp directory based on environment\n",
    "if IN_COLAB:\n",
    "    temp_dir = \"/content\"\n",
    "else:\n",
    "    # For local environments, use current directory or a temp directory\n",
    "    temp_dir = os.getcwd()\n",
    "\n",
    "# Locate all .pro files\n",
    "pro_files = glob.glob(os.path.join(ini_directory, 'output', '*.pro'))\n",
    "\n",
    "if pro_files:\n",
    "    # Copy all files to a simple location\n",
    "    downloaded_files = []\n",
    "    for pro_file in pro_files:\n",
    "        filename = os.path.basename(pro_file)\n",
    "        temp_file_path = os.path.join(temp_dir, filename)\n",
    "        shutil.copy(pro_file, temp_file_path)\n",
    "        downloaded_files.append(filename)\n",
    "\n",
    "    # Create a zip file with all .pro files\n",
    "    import zipfile\n",
    "    zip_filename = 'snowpack_profiles.zip'\n",
    "    zip_path = os.path.join(temp_dir, zip_filename)\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for filename in downloaded_files:\n",
    "            file_path = os.path.join(temp_dir, filename)\n",
    "            zipf.write(file_path, filename)\n",
    "\n",
    "    # Download the zip file (only in Colab)\n",
    "    if IN_COLAB:\n",
    "        files.download(zip_path)\n",
    "    else:\n",
    "        print(f\"Zip file created at: {zip_path}\")\n",
    "        print(f\"Files included: {', '.join(downloaded_files)}\")\n",
    "\n",
    "    # Show how to open in niViz\n",
    "    display(Markdown(f\"\"\"\n",
    "    ---\n",
    "    {len(downloaded_files)} SNOWPACK profile files have been downloaded as **`{zip_filename}`**.\n",
    "\n",
    "    Next Step \u2014 View in niViz\n",
    "    1. Go to https://run.niviz.org\n",
    "    2. Click \"File\" \u2192 \"Open Profile\" or drag any of the downloaded files into the screen\n",
    "    3. Select any of the downloaded files:\n",
    "    \"\"\"))\n",
    "\n",
    "    for filename in downloaded_files:\n",
    "        display(Markdown(f\"   - **`{filename}`**\"))\n",
    "\n",
    "else:\n",
    "    display(Markdown(\"No .pro files found in the output directory.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7EiXf6ZyXoy"
   },
   "source": [
    "# This cell can erase input and ini files to start over.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "TfiTcySpenWY"
   },
   "outputs": [],
   "source": [
    "# @title Clean up generated files\n",
    "# @markdown Run this cell to remove generated .sno and .ini files.\n",
    "\n",
    "run_cleanup = False #@param {type:\"boolean\"}\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Use variables from the configuration cell\n",
    "sno_directory_to_clear = sno_directory\n",
    "ini_directory_to_clear = ini_directory\n",
    "\n",
    "def clear_directory(directory_path):\n",
    "    \"\"\"Removes all files and subdirectories within a given directory.\n",
    "\n",
    "    Args:\n",
    "        directory_path: Path to directory to clear\n",
    "\n",
    "    Returns:\n",
    "        tuple: (success: bool, files_deleted: int, errors: list)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory not found: {directory_path}\")\n",
    "        return False, 0, []\n",
    "\n",
    "    if not os.path.isdir(directory_path):\n",
    "        print(f\"Error: {directory_path} is not a directory\")\n",
    "        return False, 0, []\n",
    "\n",
    "    # Count files before deletion\n",
    "    file_count = len([f for f in os.listdir(directory_path)\n",
    "                      if os.path.isfile(os.path.join(directory_path, f))])\n",
    "\n",
    "    print(f\"Clearing contents of: {directory_path}\")\n",
    "    print(f\"  Found {file_count} file(s) and {len([d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))])} subdirectory(ies)\")\n",
    "\n",
    "    files_deleted = 0\n",
    "    errors = []\n",
    "\n",
    "    for item in os.listdir(directory_path):\n",
    "        item_path = os.path.join(directory_path, item)\n",
    "        try:\n",
    "            if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "                os.unlink(item_path)\n",
    "                files_deleted += 1\n",
    "            elif os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)\n",
    "                files_deleted += 1\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Failed to delete {item_path}: {e}\"\n",
    "            errors.append(error_msg)\n",
    "            print(f\"  Warning: {error_msg}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"  Completed with {len(errors)} error(s)\")\n",
    "    else:\n",
    "        print(f\"  Successfully deleted {files_deleted} item(s)\")\n",
    "\n",
    "    return len(errors) == 0, files_deleted, errors\n",
    "\n",
    "if run_cleanup:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"WARNING: This will delete all files in the following directories:\")\n",
    "    print(f\"  - {sno_directory_to_clear}\")\n",
    "    print(f\"  - {ini_directory_to_clear}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Clear the input (sno) directory\n",
    "    sno_success, sno_count, sno_errors = clear_directory(sno_directory_to_clear)\n",
    "\n",
    "    # Clear the config (ini) directory\n",
    "    ini_success, ini_count, ini_errors = clear_directory(ini_directory_to_clear)\n",
    "\n",
    "    total_errors = len(sno_errors) + len(ini_errors)\n",
    "    if total_errors == 0:\n",
    "        print(\"\\n\u2713 Cleanup complete successfully.\")\n",
    "    else:\n",
    "        print(f\"\\n\u26a0 Cleanup completed with {total_errors} error(s).\")\n",
    "else:\n",
    "    print(\"Cleanup is disabled. Check the 'Run cleanup' box to enable.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}