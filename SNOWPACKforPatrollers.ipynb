{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Austfi/SNOWPACKforPatrollers/blob/main/SNOWPACKforPatrollers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install SNOWPACK and MeteoIO\n",
    "\n",
    "SNOWPACK is a physics based snowpack model developed by the Swiss WSL Institute for Snow and Avalanche Research (SLF). It is a mass and energy balance model that simulates snowpack development and evolution over time. METEOIO is a data handling library that SNOWPACK uses to read in meteorological data installed during this step. \n",
    "\n",
    "Documentaiton for SNOWPACK can be found [here](https://snowpack.slf.ch/). Documentation for MeteoIO can be found [here](https://meteoio.slf.ch/). \n",
    "\n",
    "Running the cell below will install SNOWPACK and MeteoIO along with some helper functions to generate the necessary configuration files for SNOWPACK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "step1_setup"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Installation...\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]               \n",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \n",
      "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease   \n",
      "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\n",
      "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease    \n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
      "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,572 kB] \n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
      "Fetched 34.8 MB in 5s (7,489 kB/s)                      \n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.9ubuntu3).\n",
      "liblapack-dev is already the newest version (3.10.0-2ubuntu1).\n",
      "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
      "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
      "The following NEW packages will be installed:\n",
      "  numdiff\n",
      "0 upgraded, 1 newly installed, 0 to remove and 5 not upgraded.\n",
      "Need to get 592 kB of archives.\n",
      "After this operation, 939 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 numdiff amd64 5.9.0-1 [592 kB]\n",
      "Fetched 592 kB in 2s (326 kB/s)  \n",
      "Selecting previously unselected package numdiff.\n",
      "(Reading database ... 117528 files and directories currently installed.)\n",
      "Preparing to unpack .../numdiff_5.9.0-1_amd64.deb ...\n",
      "Unpacking numdiff (5.9.0-1) ...\n",
      "Setting up numdiff (5.9.0-1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Collecting openmeteo-requests\n",
      "  Downloading openmeteo_requests-1.7.4-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests-cache\n",
      "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting retry-requests\n",
      "  Downloading retry_requests-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Collecting niquests>=3.15.2 (from openmeteo-requests)\n",
      "  Downloading niquests-3.16.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting openmeteo-sdk>=1.22.0 (from openmeteo-requests)\n",
      "  Downloading openmeteo_sdk-1.23.0-py3-none-any.whl.metadata (935 bytes)\n",
      "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (25.4.0)\n",
      "Collecting cattrs>=22.2 (from requests-cache)\n",
      "  Downloading cattrs-25.3.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (4.5.1)\n",
      "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (2.32.4)\n",
      "Collecting url-normalize>=1.4 (from requests-cache)\n",
      "  Downloading url_normalize-2.2.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.12/dist-packages (from requests-cache) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from cattrs>=22.2->requests-cache) (4.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from niquests>=3.15.2->openmeteo-requests) (3.4.4)\n",
      "Collecting urllib3-future<3,>=2.13.903 (from niquests>=3.15.2->openmeteo-requests)\n",
      "  Downloading urllib3_future-2.15.901-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting wassima<3,>=1.0.1 (from niquests>=3.15.2->openmeteo-requests)\n",
      "  Downloading wassima-2.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: flatbuffers==25.9.23 in /usr/local/lib/python3.12/dist-packages (from openmeteo-sdk>=1.22.0->openmeteo-requests) (25.9.23)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->requests-cache) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->requests-cache) (2025.11.12)\n",
      "Requirement already satisfied: h11<1.0.0,>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests) (0.16.0)\n",
      "Collecting jh2<6.0.0,>=5.0.3 (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests)\n",
      "  Downloading jh2-5.0.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting qh3<2.0.0,>=1.5.4 (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests)\n",
      "  Downloading qh3-1.5.6-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Downloading openmeteo_requests-1.7.4-py3-none-any.whl (7.0 kB)\n",
      "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading retry_requests-2.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading cattrs-25.3.0-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading niquests-3.16.1-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.8/170.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openmeteo_sdk-1.23.0-py3-none-any.whl (18 kB)\n",
      "Downloading url_normalize-2.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading urllib3_future-2.15.901-py3-none-any.whl (684 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.7/684.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wassima-2.0.3-py3-none-any.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jh2-5.0.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.1/394.1 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading qh3-1.5.6-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wassima, url-normalize, qh3, openmeteo-sdk, jh2, cattrs, urllib3-future, retry-requests, requests-cache, niquests, openmeteo-requests\n",
      "Successfully installed cattrs-25.3.0 jh2-5.0.10 niquests-3.16.1 openmeteo-requests-1.7.4 openmeteo-sdk-1.23.0 qh3-1.5.6 requests-cache-1.2.1 retry-requests-2.0.0 url-normalize-2.2.1 urllib3-future-2.15.901 wassima-2.0.3\n",
      "PPA publishes dbgsym, you may need to include 'main/debug' component\n",
      "Repository: 'deb https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu/ jammy main'\n",
      "Description:\n",
      "Toolchain test builds; see https://wiki.ubuntu.com/ToolChain\n",
      "\n",
      "More info: https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test\n",
      "Adding repository.\n",
      "Adding deb entry to /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
      "Adding disabled deb-src entry to /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
      "Adding key to /etc/apt/trusted.gpg.d/ubuntu-toolchain-r-ubuntu-test.gpg with fingerprint C8EC952E2A0E1FBDC5090F6A2C277A0A352154E5\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
      "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]               \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease               \n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease    \n",
      "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease          \n",
      "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Get:9 https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu jammy InRelease [24.6 kB]\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:11 https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu jammy/main amd64 Packages [17.4 kB]\n",
      "Fetched 45.9 kB in 2s (25.6 kB/s)    \n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
      "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]               \n",
      "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease               \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \n",
      "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease          \n",
      "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease    \n",
      "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:9 https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Fetched 3,917 B in 1s (2,742 B/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  gcc-13-base\n",
      "The following NEW packages will be installed:\n",
      "  gcc-13-base\n",
      "The following packages will be upgraded:\n",
      "  libstdc++6\n",
      "1 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
      "Need to get 811 kB of archives.\n",
      "After this operation, 564 kB of additional disk space will be used.\n",
      "Get:1 https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu jammy/main amd64 gcc-13-base amd64 13.1.0-8ubuntu1~22.04 [19.7 kB]\n",
      "Get:2 https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu jammy/main amd64 libstdc++6 amd64 13.1.0-8ubuntu1~22.04 [792 kB]\n",
      "Fetched 811 kB in 2s (340 kB/s)     \n",
      "Selecting previously unselected package gcc-13-base:amd64.\n",
      "(Reading database ... 117544 files and directories currently installed.)\n",
      "Preparing to unpack .../gcc-13-base_13.1.0-8ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking gcc-13-base:amd64 (13.1.0-8ubuntu1~22.04) ...\n",
      "Setting up gcc-13-base:amd64 (13.1.0-8ubuntu1~22.04) ...\n",
      "(Reading database ... 117549 files and directories currently installed.)\n",
      "Preparing to unpack .../libstdc++6_13.1.0-8ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libstdc++6:amd64 (13.1.0-8ubuntu1~22.04) over (12.3.0-1ubuntu1~22.04.2) ...\n",
      "Setting up libstdc++6:amd64 (13.1.0-8ubuntu1~22.04) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
      "\n",
      "--2025-12-23 20:30:41--  https://gitlabext.wsl.ch/api/v4/projects/32/packages/generic/snowpack/3.7.0/Snowpack-3.7.0-x86_64.deb\n",
      "Resolving gitlabext.wsl.ch (gitlabext.wsl.ch)... 193.134.202.7\n",
      "Connecting to gitlabext.wsl.ch (gitlabext.wsl.ch)|193.134.202.7|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 40893106 (39M) [application/octet-stream]\n",
      "Saving to: ‘snowpack.deb’\n",
      "\n",
      "snowpack.deb        100%[===================>]  39.00M  10.3MB/s    in 3.8s    \n",
      "\n",
      "2025-12-23 20:30:47 (10.3 MB/s) - ‘snowpack.deb’ saved [40893106/40893106]\n",
      "\n",
      "Selecting previously unselected package snowpack.\n",
      "(Reading database ... 117549 files and directories currently installed.)\n",
      "Preparing to unpack snowpack.deb ...\n",
      "Unpacking snowpack (3.7.0) ...\n",
      "Setting up snowpack (3.7.0) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# @title Step 1: Install & Setup (Run this once)\n",
    "\n",
    "print('[INFO] Starting Installation...')\n",
    "\n",
    "\n",
    "\n",
    "!apt-get update\n",
    "!apt-get install -y build-essential cmake git liblapack-dev numdiff\n",
    "\n",
    "%pip install openmeteo-requests requests-cache retry-requests pandas numpy ipyleaflet\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "import re\n",
    "import struct\n",
    "import tarfile\n",
    "import gzip\n",
    "import zipfile\n",
    "import subprocess\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output, FileLink, Markdown\n",
    "from ipyleaflet import Map, Marker, basemaps\n",
    "from ipywidgets import Output\n",
    "\n",
    "# Open-Meteo\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Upgrade libstdc++6 to support GLIBCXX_3.4.32 (required by Snowpack 3.7.0)\n",
    "!add-apt-repository -y ppa:ubuntu-toolchain-r/test\n",
    "!apt-get update\n",
    "!apt-get install -y libstdc++6\n",
    "\n",
    "# 2. Download official compiled binaries (Snowpack bundle includes MeteoIO)\n",
    "!wget -O snowpack.deb https://gitlabext.wsl.ch/api/v4/projects/32/packages/generic/snowpack/3.7.0/Snowpack-3.7.0-x86_64.deb\n",
    "\n",
    "# 3. Install it\n",
    "!dpkg -i --force-overwrite snowpack.deb\n",
    "!apt-get install -f -y\n",
    "\n",
    "\n",
    "\n",
    "# --- Helper Functions (Config) ---\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generate .sno and .ini configuration files for SNOWPACK simulations\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For local testing - use current directory\n",
    "if not os.path.exists(\"/content\"):\n",
    "    sno_directory = \".\"\n",
    "    ini_directory = \".\"\n",
    "\n",
    "def generate_slopes(include_flat, north_slope, east_slope, south_slope, west_slope, custom_directions, default_slope_angle):\n",
    "    \"\"\"Generate list of virtual slopes based on user selections\"\"\"\n",
    "    slopes = []\n",
    "\n",
    "    # Add flat slope if requested\n",
    "    if include_flat:\n",
    "        slopes.append((0.0, 0.0))\n",
    "\n",
    "    # Add cardinal direction slopes\n",
    "    if north_slope:\n",
    "        slopes.append((default_slope_angle, 0.0))\n",
    "    if east_slope:\n",
    "        slopes.append((default_slope_angle, 90.0))\n",
    "    if south_slope:\n",
    "        slopes.append((default_slope_angle, 180.0))\n",
    "    if west_slope:\n",
    "        slopes.append((default_slope_angle, 270.0))\n",
    "\n",
    "    # Add custom directions\n",
    "    if custom_directions.strip():\n",
    "        try:\n",
    "            custom_angles = [float(x.strip()) for x in custom_directions.split(',')]\n",
    "            for angle in custom_angles:\n",
    "                if 0 <= angle <= 360:\n",
    "                    slopes.append((default_slope_angle, angle))\n",
    "        except ValueError:\n",
    "            print(\"Warning: Invalid custom directions format. Use comma-separated numbers.\")\n",
    "\n",
    "    return slopes\n",
    "\n",
    "def to_meters(value: float, unit: str) -> float:\n",
    "    \"\"\"Normalize altitude inputs so downstream code always works in meters.\"\"\"\n",
    "    unit = unit.lower()\n",
    "    if unit == \"meters\":\n",
    "        return float(value)\n",
    "    if unit == \"feet\":\n",
    "        return float(value) * 0.3048\n",
    "    raise ValueError(f\"Unsupported altitude unit: {unit}\")\n",
    "\n",
    "\n",
    "def create_sno_content(station_id, station_name, longitude, latitude, altitude_meters, timezone, profile_date, slope_angle, slope_azimuth):\n",
    "    \"\"\"Create .sno file content for a single slope\"\"\"\n",
    "\n",
    "    content = f\"\"\"SMET 1.1 ASCII\n",
    "[HEADER]\n",
    "station_id       = {station_id}\n",
    "station_name     = {station_name}\n",
    "longitude        = {longitude}\n",
    "latitude         = {latitude}\n",
    "altitude         = {altitude_meters}\n",
    "nodata           = -999\n",
    "tz               = {timezone}\n",
    "source           = OpenMeteo\n",
    "prototype        = SNOWPACK\n",
    "ProfileDate      = {profile_date}\n",
    "HS_Last          = 0.0000\n",
    "SlopeAngle       = {slope_angle}\n",
    "SlopeAzi         = {slope_azimuth}\n",
    "nSoilLayerData   = 0\n",
    "nSnowLayerData   = 0\n",
    "SoilAlbedo       = 0.09\n",
    "BareSoil_z0      = 0.020\n",
    "CanopyHeight     = 0.00\n",
    "CanopyLeafAreaIndex = 0.00\n",
    "CanopyDirectThroughfall = 1.00\n",
    "ErosionLevel     = 0\n",
    "TimeCountDeltaHS = 0.000000\n",
    "WindScalingFactor = 1.00\n",
    "\n",
    "fields           = timestamp Layer_Thick  T  Vol_Frac_I  Vol_Frac_W  Vol_Frac_V  Vol_Frac_S Rho_S Conduc_S HeatCapac_S  rg  rb  dd  sp  mk mass_hoar ne CDot metamo\n",
    "[DATA]\n",
    "\"\"\"\n",
    "\n",
    "    return content\n",
    "\n",
    "def create_ini_content(station_id, filename, snowfiles, meas_tss, enforce_measured_snow_heights,\n",
    "                        coord_sys, coord_param, timezone, write_profiles, write_timeseries, write_snowpack):\n",
    "    \"\"\"Create .ini file content with multiple SNOWFILE entries\n",
    "\n",
    "    Args:\n",
    "        station_id: Station identifier\n",
    "        filename: SMET filename\n",
    "        snowfiles: List of .sno filenames\n",
    "        meas_tss: MEAS_TSS setting (\"true\" or \"false\")\n",
    "        enforce_measured_snow_heights: ENFORCE_MEASURED_SNOW_HEIGHTS setting (\"true\" or \"false\")\n",
    "        coord_sys: Coordinate system (e.g., \"UTM\")\n",
    "        coord_param: Coordinate parameter (e.g., \"13S\")\n",
    "        timezone: Timezone offset (e.g., -7)\n",
    "        write_profiles: PROF_WRITE setting (\"true\" or \"false\")\n",
    "        write_timeseries: TS_WRITE setting (\"true\" or \"false\")\n",
    "        write_snowpack: SNOW_WRITE setting (\"true\" or \"false\")\n",
    "\n",
    "    Returns:\n",
    "        String containing .ini file content\n",
    "    \"\"\"\n",
    "\n",
    "    content = f\"\"\"[General]\n",
    "\n",
    "[Input]\n",
    "COORDSYS = {coord_sys}\n",
    "COORDPARAM = {coord_param}\n",
    "TIME_ZONE = {timezone}\n",
    "\n",
    "METEO = SMET\n",
    "METEOPATH = ../input\n",
    "METEOFILE1 = {filename}\n",
    "\"\"\"\n",
    "\n",
    "    # Add SNOWFILE entries for each slope\n",
    "    for i, snowfile in enumerate(snowfiles, 1):\n",
    "        content += f\"SNOWFILE{i} = ../input/{snowfile}\\n\"\n",
    "\n",
    "    content += f\"\"\"\n",
    "[Output]\n",
    "COORDSYS = {coord_sys}\n",
    "COORDPARAM = {coord_param}\n",
    "TIME_ZONE = {timezone}\n",
    "METEOPATH = ./output\n",
    "EXPERIMENT = res\n",
    "SNOW_WRITE = {write_snowpack.lower()}\n",
    "\n",
    "TS_WRITE = {write_timeseries.lower()}\n",
    "TS_FORMAT = SMET\n",
    "TS_START = 0.0\n",
    "TS_DAYS_BETWEEN = 0.125\n",
    "PROF_WRITE = {write_profiles.lower()}\n",
    "PROF_FORMAT = PRO\n",
    "AGGREG_PRF = false\n",
    "PROF_START = 0.0\n",
    "PROF_DAYS_BETWEEN = 0.125\n",
    "\n",
    "[Snowpack]\n",
    "MEAS_TSS = {meas_tss.lower()}\n",
    "ENFORCE_MEASURED_SNOW_HEIGHTS = {enforce_measured_snow_heights.lower()}\n",
    "FORCING = ATMOS\n",
    "SW_MODE = INCOMING\n",
    "MEAS_INCOMING_LONGWAVE = false\n",
    "HEIGHT_OF_WIND_VALUE = 10\n",
    "HEIGHT_OF_METEO_VALUES = 2\n",
    "ATMOSPHERIC_STABILITY = NEUTRAL\n",
    "ROUGHNESS_LENGTH = 0.002\n",
    "CALCULATION_STEP_LENGTH = 30.0\n",
    "CHANGE_BC = false\n",
    "THRESH_CHANGE_BC = -1.0\n",
    "SNP_SOIL = false\n",
    "SOIL_FLUX = false\n",
    "GEO_HEAT = 0.06\n",
    "CANOPY = false\n",
    "\n",
    "[SnowpackAdvanced]\n",
    "FIXED_POSITIONS = 0.25 0.5 1.0 -0.25 -0.10\n",
    "WIND_SCALING_FACTOR = 1.0\n",
    "NUMBER_SLOPES = {len(snowfiles)}\n",
    "SNOW_REDISTRIBUTION = TRUE\n",
    "THRESH_RAIN = 1.4\n",
    "T_CRAZY_MIN = 140\n",
    "T_CRAZY_MAX = 360\n",
    "\n",
    "[Filters]\n",
    "ENABLE_METEO_FILTERS = true\n",
    "PSUM::filter1 = min\n",
    "PSUM::arg1::soft = true\n",
    "PSUM::arg1::min = 0.0\n",
    "TA::filter1 = min_max\n",
    "TA::arg1::min = 240\n",
    "TA::arg1::max = 320\n",
    "RH::filter1 = min_max\n",
    "RH::arg1::min = 0.01\n",
    "RH::arg1::max = 1.2\n",
    "RH::filter2 = min_max\n",
    "RH::arg2::soft = true\n",
    "RH::arg2::min = 0.05\n",
    "RH::arg2::max = 1.0\n",
    "ISWR::filter1 = min_max\n",
    "ISWR::arg1::min = -10\n",
    "ISWR::arg1::max = 1500\n",
    "ISWR::filter2 = min_max\n",
    "ISWR::arg2::soft = true\n",
    "ISWR::arg2::min = 0\n",
    "ISWR::arg2::max = 1500\n",
    "RSWR::filter1 = min_max\n",
    "RSWR::arg1::min = -10\n",
    "RSWR::arg1::max = 1500\n",
    "RSWR::filter2 = min_max\n",
    "RSWR::arg2::soft = true\n",
    "RSWR::arg2::min = 0\n",
    "RSWR::arg2::max = 1500\n",
    "ILWR::filter1 = min_max\n",
    "ILWR::arg1::min = 188\n",
    "ILWR::arg1::max = 600\n",
    "ILWR::filter2 = min_max\n",
    "ILWR::arg2::soft = true\n",
    "ILWR::arg2::min = 200\n",
    "ILWR::arg2::max = 400\n",
    "TSS::filter1 = min_max\n",
    "TSS::arg1::min = 200\n",
    "TSS::arg1::max = 320\n",
    "TSG::filter1 = min_max\n",
    "TSG::arg1::min = 200\n",
    "TSG::arg1::max = 320\n",
    "HS::filter1 = min\n",
    "HS::arg1::soft = true\n",
    "HS::arg1::min = 0.0\n",
    "HS::filter2 = rate\n",
    "HS::arg2::max = 5.55e-5\n",
    "VW::filter1 = min_max\n",
    "VW::arg1::min = -2\n",
    "VW::arg1::max = 70\n",
    "VW::filter2 = min_max\n",
    "VW::arg2::soft = true\n",
    "VW::arg2::min = 0.0\n",
    "VW::arg2::max = 50.0\n",
    "\n",
    "[Interpolations1D]\n",
    "MAX_GAP_SIZE = 86400\n",
    "PSUM::resample1 = accumulate\n",
    "PSUM::ACCUMULATE::PERIOD = 1800\n",
    "HS::resample1 = linear\n",
    "HS::LINEAR::MAX_GAP_SIZE = 43200\n",
    "VW::resample1 = linear\n",
    "DW::resample1 = linear\n",
    "ILWR::RESAMPLE1=LINEAR\n",
    "ISWR::RESAMPLE1=LINEAR\n",
    "RH::RESAMPLE1=LINEAR\n",
    "TA::RESAMPLE1=LINEAR\n",
    "\n",
    "[Generators]\n",
    "ILWR::generator1 = AllSky_LW\n",
    "ILWR::arg1::type = Carmona\n",
    "ILWR::arg1::shade_from_dem = FALSE\n",
    "ILWR::arg1::use_rswr = FALSE\n",
    "ILWR::generator2 = ClearSky_LW\n",
    "ILWR::arg2::type = Dilley\n",
    "\"\"\"\n",
    "\n",
    "    return content\n",
    "\n",
    "def get_slope_filename(angle, azimuth, slope_index, include_flat, station_id):\n",
    "    \"\"\"Get filename for slope naming convention.\n",
    "\n",
    "    Naming rules:\n",
    "    - Flat slope (angle == 0.0): Returns 'keystone' (no number)\n",
    "    - Non-flat slopes: Returns 'keystone1', 'keystone2', etc.\n",
    "    - Numbering depends on whether flat slope is included:\n",
    "      * If flat included: non-flat slopes start from index 1\n",
    "      * If flat not included: all slopes start from index 1\n",
    "\n",
    "    Args:\n",
    "        angle: Slope angle in degrees (0.0 for flat)\n",
    "        azimuth: Slope azimuth in degrees\n",
    "        slope_index: Index of slope in the slopes list\n",
    "        include_flat: Whether flat slope is included in the list\n",
    "\n",
    "    Returns:\n",
    "        Filename base (without .sno extension)\n",
    "    \"\"\"\n",
    "    if angle == 0.0:\n",
    "        return station_id  # Flat slope gets no number\n",
    "    else:\n",
    "        # For numbered slopes, determine the number based on position\n",
    "        if include_flat:\n",
    "            # If flat is included, non-flat slopes start from index 1\n",
    "            return f\"{station_id}{slope_index}\"\n",
    "        else:\n",
    "            # If no flat, start numbering from 1\n",
    "            return f\"{station_id}{slope_index + 1}\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "\n",
    "    print(\"SNOWPACK Configuration Files Generation\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Station: {station_name} ({station_id})\")\n",
    "    print(f\"Location: {latitude:.6f}°N, {longitude:.6f}°W, {altitude_meters}m\")\n",
    "    print(f\"Sno Directory: {sno_directory}\")\n",
    "    print(f\"Ini Directory: {ini_directory}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if not generate_config_files:\n",
    "        print(\"Configuration generation disabled. Set 'generate_config_files' to True to generate files.\")\n",
    "        return\n",
    "\n",
    "    # Validate profile_date format\n",
    "    try:\n",
    "        datetime.strptime(profile_date, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    except ValueError:\n",
    "        print(f\"Warning: profile_date format may be incorrect. Expected format: YYYY-MM-DDTHH:MM:SS\")\n",
    "        print(f\"  Current value: {profile_date}\")\n",
    "\n",
    "    # Validate directories\n",
    "    try:\n",
    "        os.makedirs(sno_directory, exist_ok=True)\n",
    "        os.makedirs(ini_directory, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directories: {e}\")\n",
    "        return\n",
    "\n",
    "    # Generate slopes\n",
    "    slopes = generate_slopes(include_flat, north_slope, east_slope, south_slope, west_slope, custom_directions, default_slope_angle)\n",
    "\n",
    "    # Limit to requested number of slopes\n",
    "    if len(slopes) > num_slopes:\n",
    "        slopes = slopes[:num_slopes]\n",
    "        print(f\"Warning: Limited to {num_slopes} slopes as requested\")\n",
    "\n",
    "    # Create multiple .sno files and collect snowfile names\n",
    "    snowfiles = []\n",
    "    sno_files_created = []\n",
    "\n",
    "    for i, (angle, azimuth) in enumerate(slopes):\n",
    "        # Get filename based on new naming convention\n",
    "        sno_filename = get_slope_filename(angle, azimuth, i, include_flat, station_id) + \".sno\"\n",
    "        snowfiles.append(sno_filename)\n",
    "\n",
    "        # Create .sno content for this slope\n",
    "        sno_content = create_sno_content(station_id, station_name, longitude, latitude, altitude_meters, timezone, profile_date, angle, azimuth)\n",
    "\n",
    "        # Write .sno file to input directory\n",
    "        sno_filepath = os.path.join(sno_directory, sno_filename)\n",
    "        try:\n",
    "            with open(sno_filepath, \"w\") as f:\n",
    "                f.write(sno_content)\n",
    "            sno_files_created.append(sno_filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing {sno_filepath}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Create .ini content with multiple SNOWFILE entries\n",
    "    ini_content = create_ini_content(\n",
    "        station_id,\n",
    "        f\"{station_id}.smet\",\n",
    "        snowfiles,\n",
    "        meas_tss,\n",
    "        enforce_measured_snow_heights,\n",
    "        coord_sys,\n",
    "        coord_param,\n",
    "        timezone,\n",
    "        write_profiles,\n",
    "        write_timeseries,\n",
    "        write_snowpack\n",
    "    )\n",
    "\n",
    "    # Write .ini file to keystone directory\n",
    "    ini_filename = os.path.join(ini_directory, f\"{station_id}.ini\")\n",
    "    try:\n",
    "        with open(ini_filename, \"w\") as f:\n",
    "            f.write(ini_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing {ini_filename}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Display results\n",
    "    print(f\"\\n Configuration files created:\")\n",
    "    print(f\"   .ini file: {ini_filename}\")\n",
    "    print(f\"   .sno files:\")\n",
    "    for sno_file in sno_files_created:\n",
    "        print(f\"     {sno_file}\")\n",
    "\n",
    "    print(f\"\\nVirtual slopes configured: {len(slopes)}\")\n",
    "    for i, (angle, azimuth) in enumerate(slopes):\n",
    "        sno_filename = get_slope_filename(angle, azimuth, i, include_flat, station_id)\n",
    "        if angle == 0.0:\n",
    "            print(f\"   Slope {i+1}: Flat (0°) -> {sno_filename}.sno\")\n",
    "        else:\n",
    "            direction = \"\"\n",
    "            if azimuth == 0.0:\n",
    "                direction = \"North\"\n",
    "            elif azimuth == 90.0:\n",
    "                direction = \"East\"\n",
    "            elif azimuth == 180.0:\n",
    "                direction = \"South\"\n",
    "            elif azimuth == 270.0:\n",
    "                direction = \"West\"\n",
    "            else:\n",
    "                direction = f\"{azimuth}°\"\n",
    "            print(f\"   Slope {i+1}: {angle}° slope facing {direction} -> {sno_filename}.sno\")\n",
    "\n",
    "    print(f\"\\nSNOWPACK settings:\")\n",
    "    print(f\"   MEAS_TSS = {meas_tss}\")\n",
    "    print(f\"   ENFORCE_MEASURED_SNOW_HEIGHTS = {enforce_measured_snow_heights}\")\n",
    "    print(f\"   NUMBER_SLOPES = {len(slopes)}\")\n",
    "\n",
    "    print(\"\\n [INFO] SNOWPACK configuration generation complete.\")\n",
    "\n",
    "# Run the main function\n",
    "\n",
    "\n",
    "# --- Helper Functions (SMET) ---\n",
    "\n",
    "\n",
    "\n",
    "# Pulling from the configuration cell\n",
    "\n",
    "# Pulling from the configuration cell\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Helper functions ----------------------------------------------------\n",
    "\n",
    "# Imports for SNODAS\n",
    "\n",
    "def get_snodas_snow_depth(lat, lon, date_str, cache_dir=\"snodas_cache\", debug=False):\n",
    "    \"\"\"\n",
    "    Download and extract SNODAS snow depth from NSIDC.\n",
    "    \n",
    "    SNODAS Units:\n",
    "    - Raw data: millimeters (mm) stored as integer (snow_depth_raw / 1000.0)\n",
    "    - Returns: meters (m) as float\n",
    "    \n",
    "    This is different from Open-Meteo which returns centimeters (cm).\n",
    "    \"\"\"\n",
    "    SNODAS_NODATA = -9999\n",
    "    \n",
    "    # Grid configurations (detected from file size)\n",
    "    GRID_CONFIGS = {\n",
    "        'old': {'XMIN': -124.73375000000000, 'YMAX': 52.87458333333333, \n",
    "                'XMAX': -66.94208333333333, 'YMIN': 24.94958333333333,\n",
    "                'NCOLS': 6935, 'NROWS': 3351, 'name': 'Pre-Oct-2013'},\n",
    "        'new': {'XMIN': -124.73333333333333, 'YMAX': 52.87500000000000,\n",
    "                'XMAX': -66.94166666666667, 'YMIN': 24.95000000000000,\n",
    "                'NCOLS': 3353, 'NROWS': 3353, 'name': 'Post-Oct-2013'}\n",
    "    }\n",
    "    \n",
    "    # Check location bounds\n",
    "    if lat < 24.95 or lat > 52.88 or lon < -124.74 or lon > -66.94:\n",
    "        return None\n",
    "    \n",
    "    # Construct URL\n",
    "    tar_filename = f\"SNODAS_{date_str}.tar\"\n",
    "    data_base = \"https://noaadata.apps.nsidc.org/NOAA/G02158/masked\"\n",
    "    year = date_str[:4]\n",
    "    month = date_str[4:6]\n",
    "    month_names = [\"01_Jan\", \"02_Feb\", \"03_Mar\", \"04_Apr\", \"05_May\", \"06_Jun\",\n",
    "                   \"07_Jul\", \"08_Aug\", \"09_Sep\", \"10_Oct\", \"11_Nov\", \"12_Dec\"]\n",
    "    month_dir = month_names[int(month) - 1]\n",
    "    data_url = f\"{data_base}/{year}/{month_dir}/{tar_filename}\"\n",
    "    \n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    cache_path = os.path.join(cache_dir, tar_filename)\n",
    "    \n",
    "    try:\n",
    "        # Download or use cache\n",
    "        if os.path.exists(cache_path):\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                tar_data = BytesIO(f.read())\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f\"  Downloading {date_str}...\")\n",
    "            # Set a user-agent to avoid potential 403s\n",
    "            req = urllib.request.Request(\n",
    "                data_url, \n",
    "                headers={'User-Agent': 'Mozilla/5.0'}\n",
    "            )\n",
    "            with urllib.request.urlopen(req, timeout=60) as response:\n",
    "                tar_data = BytesIO(response.read())\n",
    "                with open(cache_path, 'wb') as f:\n",
    "                    f.write(tar_data.getvalue())\n",
    "            tar_data.seek(0)\n",
    "        \n",
    "        # Extract and decompress\n",
    "        with tarfile.open(fileobj=tar_data, mode='r') as tar:\n",
    "            # Look for the .dat.gz file with the snow depth code (1036)\n",
    "            snow_depth_gz_file = None\n",
    "            for member in tar.getmembers():\n",
    "                if '1036' in member.name and member.name.endswith('.dat.gz'):\n",
    "                    snow_depth_gz_file = tar.extractfile(member)\n",
    "                    break\n",
    "            \n",
    "            if snow_depth_gz_file is None:\n",
    "                if debug: print(\"  Could not find snow depth file (1036) in tar archive\")\n",
    "                return None\n",
    "        \n",
    "            with gzip.open(snow_depth_gz_file, 'rb') as gz_file:\n",
    "                data = gz_file.read()\n",
    "        \n",
    "        # Detect grid from file size\n",
    "        num_values = len(data) // 2\n",
    "        grid_config = None\n",
    "        for config in GRID_CONFIGS.values():\n",
    "            if num_values == config['NCOLS'] * config['NROWS']:\n",
    "                grid_config = config\n",
    "                break\n",
    "        \n",
    "        if grid_config is None:\n",
    "            if debug: print(f\"  Could not detect grid configuration for size {len(data)}\")\n",
    "            return None\n",
    "        \n",
    "        # Parse binary data\n",
    "        SNODAS_NCOLS = grid_config['NCOLS']\n",
    "        SNODAS_NROWS = grid_config['NROWS']\n",
    "        values = struct.unpack(f\">{SNODAS_NCOLS * SNODAS_NROWS}h\", data)\n",
    "        snow_depth_array = np.array(values).reshape((SNODAS_NROWS, SNODAS_NCOLS))\n",
    "        \n",
    "        # Calculate grid coordinates\n",
    "        SNODAS_XMIN = grid_config['XMIN']\n",
    "        SNODAS_YMAX = grid_config['YMAX']\n",
    "        SNODAS_CELLSIZE_X = (grid_config['XMAX'] - SNODAS_XMIN) / SNODAS_NCOLS\n",
    "        SNODAS_CELLSIZE_Y = (SNODAS_YMAX - grid_config['YMIN']) / SNODAS_NROWS\n",
    "        \n",
    "        col = int((lon - SNODAS_XMIN) / SNODAS_CELLSIZE_X)\n",
    "        row = int((SNODAS_YMAX - lat) / SNODAS_CELLSIZE_Y)\n",
    "        \n",
    "        col = max(0, min(SNODAS_NCOLS - 1, col))\n",
    "        row = max(0, min(SNODAS_NROWS - 1, row))\n",
    "        \n",
    "        # Extract value\n",
    "        snow_depth_raw = snow_depth_array[row, col]\n",
    "        if snow_depth_raw == SNODAS_NODATA or snow_depth_raw < 0:\n",
    "            return None\n",
    "        \n",
    "        snow_depth_m = snow_depth_raw / 1000.0\n",
    "        return snow_depth_m if snow_depth_m >= 0.0 else 0.0\n",
    "            \n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"  Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def resolve_openmeteo_elevation(mode: str, station_alt_m: float) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Decide which elevation to send to the Open-Meteo API.\n",
    "    - use_model_elevation     -> None (API uses its DEM; statistical downscaling stays enabled)\n",
    "    - use_selected_altitude   -> the altitude value converted to meters above\n",
    "    \"\"\"\n",
    "    mode = mode.lower()\n",
    "    if mode == \"use_model_elevation\":\n",
    "        return None\n",
    "    if mode == \"use_selected_altitude\":\n",
    "        return float(station_alt_m)\n",
    "    raise ValueError(f\"Unknown elevation mode: {mode}\")\n",
    "\n",
    "\n",
    "def create_smet_from_weather_data(weather_df: pd.DataFrame,\n",
    "                                  output_path: str,\n",
    "                                  station_id: str,\n",
    "                                  station_name: str,\n",
    "                                  latitude: float,\n",
    "                                  longitude: float,\n",
    "                                  altitude_meters: float,\n",
    "                                  timezone: float = -7) -> None:\n",
    "    \"\"\"\n",
    "    Create a SMET file from a weather DataFrame and write it to disk.\n",
    "\n",
    "    Args:\n",
    "        weather_df: DataFrame containing weather data with timestamp column\n",
    "        output_path: Path where SMET file will be written\n",
    "        station_id: Station identifier\n",
    "        station_name: Station name\n",
    "        latitude: Latitude in degrees\n",
    "        longitude: Longitude in degrees\n",
    "        altitude_meters: Altitude in meters\n",
    "        timezone: Timezone offset (default: -7 for Mountain Time)\n",
    "    \"\"\"\n",
    "    if \"timestamp\" in weather_df.columns:\n",
    "        weather_df = weather_df.copy()\n",
    "        weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    else:\n",
    "        weather_df = weather_df.copy()\n",
    "        weather_df.reset_index(inplace=True)\n",
    "        weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "\n",
    "    fields = [\"timestamp\", \"TA\", \"RH\", \"TSG\", \"VW\", \"DW\", \"ISWR\", \"PSUM\"]\n",
    "    if \"HS\" in weather_df.columns:\n",
    "        fields.append(\"HS\")\n",
    "\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"SMET 1.1 ASCII\\n\")\n",
    "        f.write(\"[HEADER]\\n\")\n",
    "        f.write(f\"station_id = {station_id}\\n\")\n",
    "        f.write(f\"station_name = {station_name}\\n\")\n",
    "        f.write(f\"latitude = {latitude:.10f}\\n\")\n",
    "        f.write(f\"longitude = {longitude:.10f}\\n\")\n",
    "        f.write(f\"altitude = {altitude_meters}\\n\")\n",
    "        f.write(\"nodata = -777\\n\")\n",
    "        f.write(f\"Tz = {timezone}\\n\")\n",
    "        fields_str = \"\\t\".join(fields)\n",
    "        f.write(f\"fields = {fields_str}\\n\")\n",
    "\n",
    "        field_count = len(fields)\n",
    "        units_offset = [\"0\"] * field_count\n",
    "        units_multiplier = [\"1\"] * field_count\n",
    "        f.write(f\"units_offset     = {' '.join(units_offset)}\\n\")\n",
    "        f.write(f\"units_multiplier = {' '.join(units_multiplier)}\\n\")\n",
    "\n",
    "        f.write(\"[DATA]\\n\")\n",
    "        for _, row in weather_df.iterrows():\n",
    "            values = []\n",
    "            for field in fields:\n",
    "                if field == \"timestamp\":\n",
    "                    values.append(row[field].strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "                else:\n",
    "                    val = row.get(field, -777)\n",
    "                    if pd.isna(val):\n",
    "                        val = -777\n",
    "                    values.append(f\"{val:.2f}\")\n",
    "            f.write(\"\\t\".join(values) + \"\\n\")\n",
    "\n",
    "\n",
    "def fetch_openmeteo_historical(lat: float,\n",
    "                               lon: float,\n",
    "                               start_date: str,\n",
    "                               end_date: str,\n",
    "                               model: str = \"gfs_global\",\n",
    "                               elevation: Optional[float] = None) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fetch historical forecast data from the Open-Meteo API.\n",
    "    \"\"\"\n",
    "    cache_session = requests_cache.CachedSession(\".cache\", expire_after=3600)\n",
    "    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "    url = \"https://historical-forecast-api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"relative_humidity_2m\",\n",
    "            \"wind_speed_10m\",\n",
    "            \"wind_direction_10m\",\n",
    "            \"snow_depth\",\n",
    "            \"direct_radiation\",\n",
    "            \"precipitation\",\n",
    "        ],\n",
    "        \"models\": model,\n",
    "        \"wind_speed_unit\": \"ms\",\n",
    "        \"timezone\": \"GMT\",\n",
    "    }\n",
    "\n",
    "    if elevation is not None:\n",
    "        params[\"elevation\"] = elevation\n",
    "\n",
    "    print(f\"Fetching {model} data for {lat}, {lon} from {start_date} to {end_date}\")\n",
    "    if \"elevation\" in params:\n",
    "        print(f\"Open-Meteo elevation parameter: {params['elevation']} (m)\")\n",
    "\n",
    "    try:\n",
    "        responses = openmeteo.weather_api(url, params=params)\n",
    "        response = responses[0]\n",
    "\n",
    "        print(f\"Coordinates: {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "        print(f\"Elevation: {response.Elevation()} m asl\")\n",
    "\n",
    "        hourly = response.Hourly()\n",
    "        hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "        hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "        hourly_wind_speed_10m = hourly.Variables(2).ValuesAsNumpy()\n",
    "        hourly_wind_direction_10m = hourly.Variables(3).ValuesAsNumpy()\n",
    "        hourly_snow_depth = hourly.Variables(4).ValuesAsNumpy()\n",
    "        hourly_direct_radiation = hourly.Variables(5).ValuesAsNumpy()\n",
    "        hourly_precipitation = hourly.Variables(6).ValuesAsNumpy()\n",
    "\n",
    "        time_index = pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"timestamp\": time_index,\n",
    "                \"TA\": hourly_temperature_2m + 273.15,   # Convert to Kelvin\n",
    "                \"RH\": hourly_relative_humidity_2m / 100.0,\n",
    "                \"VW\": hourly_wind_speed_10m,\n",
    "                \"DW\": hourly_wind_direction_10m,\n",
    "                \"HS\": hourly_snow_depth,\n",
    "                \"ISWR\": hourly_direct_radiation,\n",
    "                \"PSUM\": hourly_precipitation,\n",
    "            }\n",
    "        )\n",
    "        # TSG (ground temperature) is not available from Open-Meteo API\n",
    "        # Using assumed value of 273.15 K (0°C) as a reasonable default\n",
    "        # SNOWPACK will calculate actual ground temperature during simulation\n",
    "        df[\"TSG\"] = 273.15\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        print(f\"Fetched {len(df)} records\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📍 Click anywhere on the map to select your simulation location.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3453422b0234e0997cacee01f4b39ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[39.5633531658293, -105.91506958007814], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e33a395546f498685cf27d401f5453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current: 39.5634, -105.9151 | 3722m | 13S\n"
     ]
    }
   ],
   "source": [
    "# @title Location Picker\n",
    "# @markdown Click the map to select location. Altitude and UTM zone will be auto-detected.\n",
    "\n",
    "# Helper: Get UTM zone\n",
    "def get_utm_zone(lat, lon):\n",
    "    zone_number = int((lon + 180) / 6) + 1\n",
    "    if lat >= 40:\n",
    "        band = 'T'\n",
    "    elif lat >= 32:\n",
    "        band = 'S'\n",
    "    elif lat >= 24:\n",
    "        band = 'R'\n",
    "    else:\n",
    "        band = 'N'\n",
    "    return \"UTM\", f\"{zone_number}{band}\"\n",
    "\n",
    "# Helper: Get elevation from Open-Meteo\n",
    "def get_elevation(lat, lon):\n",
    "    try:\n",
    "        url = f\"https://api.open-meteo.com/v1/elevation?latitude={lat}&longitude={lon}\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        data = response.json()\n",
    "        return data.get('elevation', [None])[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Initialize defaults\n",
    "try:\n",
    "    current_lat, current_lon = latitude, longitude\n",
    "except NameError:\n",
    "    current_lat, current_lon = 39.71438, -105.84475\n",
    "\n",
    "latitude, longitude = current_lat, current_lon\n",
    "altitude_meters = get_elevation(latitude, longitude) or 3500  # Default if API fails\n",
    "coord_sys, coord_param = get_utm_zone(latitude, longitude)\n",
    "\n",
    "# Create map\n",
    "m = Map(center=(latitude, longitude), zoom=11, basemap=basemaps.OpenStreetMap.Mapnik, layout={'height': '400px'})\n",
    "marker = Marker(location=(latitude, longitude), draggable=False)\n",
    "m.add_layer(marker)\n",
    "\n",
    "status = Output()\n",
    "\n",
    "def handle_click(**kwargs):\n",
    "    global latitude, longitude, altitude_meters, coord_sys, coord_param, marker\n",
    "    if kwargs.get('type') == 'click':\n",
    "        coords = kwargs.get('coordinates')\n",
    "        latitude, longitude = coords[0], coords[1]\n",
    "        \n",
    "        # Auto-fetch elevation and UTM\n",
    "        altitude_meters = get_elevation(latitude, longitude) or altitude_meters\n",
    "        coord_sys, coord_param = get_utm_zone(latitude, longitude)\n",
    "        \n",
    "        # Update marker\n",
    "        m.remove_layer(marker)\n",
    "        marker = Marker(location=(latitude, longitude), draggable=False)\n",
    "        m.add_layer(marker)\n",
    "        \n",
    "        # Show results\n",
    "        with status:\n",
    "            status.clear_output()\n",
    "            print(\"LOCATION:\")\n",
    "            print(f\"   Latitude:   {latitude:.6f}\")\n",
    "            print(f\"   Longitude:  {longitude:.6f}\")\n",
    "            print(f\"   Elevation:  {altitude_meters:.0f} m ({altitude_meters * 3.281:.0f} ft)\")\n",
    "            print(f\"   UTM Zone:   {coord_param}\")\n",
    "\n",
    "m.on_interaction(handle_click)\n",
    "\n",
    "# Initial display\n",
    "print(\"Click anywhere on the map to select your simulation location.\\n\")\n",
    "display(m)\n",
    "display(status)\n",
    "\n",
    "# Show initial values\n",
    "print(f\"\\nCurrent: {latitude:.4f}, {longitude:.4f} | {altitude_meters:.0f}m | {coord_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Your SNOWPACK Simulation\n",
    "\n",
    "### Understanding Virtual Slopes & Time Steps\n",
    "\n",
    "### 1. Virtual Slopes\n",
    "This tool simulates not just a flat field, but virtual slopes around your station. By simulating 4 aspects (N, E, S, W) plus Flat, you get a holistic view of the avalanche problems in your zone from a single virutal weather station. \n",
    "\n",
    "### 2. Configuration and Inpute Files\n",
    "This cell with generate the .ini, .sno, and .smet files needed to run SNOWPACK. \n",
    "\n",
    "#### .ini File\n",
    "The .ini file is the main configuration file for SNOWPACK. It defines the input and output files and the parameters for the simulation. This file is based on the master file used by the CAA/CAIC for their SNOWPACK model dashboard found at https://snowpack.avalanche.ca and https://snowpack.avalanche.ca/co\n",
    "\n",
    "#### .sno File\n",
    "The .sno file is the snowpack input file for SNOWPACK. It defines the starting conditions for the snowpack simulation. This notebook is setup to start with zero snow depth and a flat surface.\n",
    "\n",
    "#### .smet File\n",
    "The .smet file is the meteorological input file for SNOWPACK. It defines the meteorological conditions for the snowpack simulation. This notebook is setup to use the OpenMeteo API to get the meteorological conditions for the station. OpenMeteo is a free and open-source weather API that provides historical and forecasted weather data. The data used is not from a weather station, but a point location within the model data simulating a virtual weather station. Resolution for these models is 3km or greater and is not accurate to the actual conditions at the location. OpenMeteo does not provide incoming longwave radiation data in their API, so this is interpolated by MeteoIO from recommendations based on the AvaCollabra working group (https://avacollabra.org/Best-practices-for-configuring-the-SNOWPACK-model/). Ground temperature is not provided by OpenMeteo and the .smet file is generated with a fixed value of 0.0 degrees Celsius (273.15 K).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "form",
    "id": "step2_config"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMET Generation Parameters\n",
      "==================================================\n",
      "Location: 39.5633531658293, -105.91506958007814\n",
      "Altitude input: 3722 m (12212 ft)\n",
      "Station: watrous_E_NTL\n",
      "Period: 2024-11-01 to 2025-04-30\n",
      "Model: ifs\n",
      "Generate: True\n",
      "Open-Meteo elevation: 3722.00 m (selected altitude)\n",
      "==================================================\n",
      "[INFO] Setup Complete. Proceed to Step 2.\n"
     ]
    }
   ],
   "source": [
    "# @title Step 2: Configure Simulation\n",
    "# Note: All times are now processed in UTC (Zulu) to ensure consistency.\n",
    "\n",
    "#@markdown ## Station Configuration\n",
    "station_id = \"watrous\"  #@param {\"type\":\"string\"}\n",
    "station_name = \"watrous_E_NTL\"  #@param {\"type\":\"string\"}\n",
    "timezone = 0  # Forced to UTC (Zulu)\n",
    "profile_date = \"2024-11-01T00:00:00\"  #@param {\"type\":\"string\"}\n",
    "# ## Virtual Slopes Configuration\n",
    "num_slopes = 5\n",
    "include_flat = True\n",
    "default_slope_angle = 38.0\n",
    "# ## Slope Directions (degrees: 0=North, 90=East, 180=South, 270=West)\n",
    "north_slope = True\n",
    "east_slope = True\n",
    "south_slope = True\n",
    "west_slope = True\n",
    "custom_directions = \"\"\n",
    "#@markdown ## SNOWPACK Settings\n",
    "meas_tss = \"false\"\n",
    "enforce_measured_snow_heights = \"false\"\n",
    "write_profiles = \"true\"\n",
    "write_timeseries = \"false\"\n",
    "write_snowpack = \"false\"\n",
    "#@markdown ## Output Configuration\n",
    "sno_directory = \"/content/input\"  #@param {\"type\":\"string\"}\n",
    "ini_directory = \"/content/config\"  #@param {\"type\":\"string\"}\n",
    "generate_config_files = True\n",
    "# @markdown ### SNOWPACK Run End Date\n",
    "snowpack_end_date_input = \"2025-04-01\"  # @param {type:\"date\"}\n",
    "\n",
    "\n",
    "# @markdown ### Location Settings are used from above.\n",
    "# latitude = 39.56858687967004  # @param {type:\"number\"}\n",
    "# longitude = -105.91900397453021  # @param {type:\"number\"}\n",
    "# altitude_input = 3614  # @param {type:\"number\"}\n",
    "# altitude_unit = \"meters\"  # @param [\"meters\", \"feet\"]\n",
    "# @markdown ### Station Information is used from above.\n",
    "# station_name = \"keystone_model\"  # @param {type:\"string\"}\n",
    "# @markdown ### Time Period\n",
    "start_date = \"2024-11-01\"  # @param {type:\"date\"}\n",
    "end_date = \"2025-04-30\"    # @param {type:\"date\"}\n",
    "# @markdown ### Weather Model\n",
    "model_selection = \"ifs\" # @param [\"nbm\", \"ifs\", \"gfs\", \"hrrr\", \"nam\"]\n",
    "# @markdown ### HS (Snow Depth) Source\n",
    "hs_source = \"model\"  # @param [\"model\", \"snodas\"]\n",
    "# ### Open-Meteo Elevation\n",
    "openmeteo_elevation_mode = \"use_selected_altitude\"\n",
    "# ### SMET Generation\n",
    "generate_files = True\n",
    "\n",
    "snowpack_end_date = f\"{snowpack_end_date_input}T00:00\"\n",
    "\n",
    "# --- Derived values / summary -------------------------------------------\n",
    "\n",
    "# Validate dates\n",
    "try:\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    if start_dt >= end_dt:\n",
    "        raise ValueError(f\"start_date ({start_date}) must be before end_date ({end_date})\")\n",
    "except ValueError as e:\n",
    "    print(f\"Date validation error: {e}\")\n",
    "    print(\"Please check your date inputs and try again.\")\n",
    "    raise\n",
    "\n",
    "# Validate that altitude_meters is available (from configuration cell)\n",
    "try:\n",
    "    altitude_meters\n",
    "except NameError:\n",
    "    print(\"Error: altitude_meters not found. Please run the configuration cell first.\")\n",
    "    raise\n",
    "\n",
    "openmeteo_elevation = resolve_openmeteo_elevation(openmeteo_elevation_mode, altitude_meters)\n",
    "\n",
    "print(\"SMET Generation Parameters\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Location: {latitude}, {longitude}\")\n",
    "print(f\"Altitude input: {altitude_meters:.0f} m ({altitude_meters * 3.281:.0f} ft)\")\n",
    "print(f\"Station: {station_name}\")\n",
    "print(f\"Period: {start_date} to {end_date}\")\n",
    "print(f\"Model: {model_selection}\")\n",
    "print(f\"Generate: {generate_files}\")\n",
    "if openmeteo_elevation is None:\n",
    "    print(\"Open-Meteo elevation: model elevation (automatic downscaling)\")\n",
    "else:\n",
    "    print(f\"Open-Meteo elevation: {openmeteo_elevation:.2f} m (selected altitude)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "print('[INFO] Setup Complete. Proceed to Step 2.')\n",
    "\n",
    "# Ensure profile_date matches start_date with time for correct initialization\n",
    "profile_date = f\"{start_date}T00:00:00\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running SNOWPACK\n",
    "\n",
    "When you run the next cell, it will:\n",
    "\n",
    "1. Download the weather data from OpenMeteo\n",
    "2. Create a .ini file and .sno file\n",
    "2. Create a SMET file from the weather data\n",
    "3. Run SNOWPACK\n",
    "4. Create five .pro files for the snowpack output from the N, E, S, W, and flat virtual slopes. \n",
    "5. Downloads a zip file of the .pro files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "id": "step3_run"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VERSION] Step 3 v3 - includes 2-day data buffer fix\n",
      "[INFO] Generative Configuration Files...\n",
      "SNOWPACK Configuration Files Generation\n",
      "==================================================\n",
      "Station: watrous_E_NTL (watrous)\n",
      "Location: 39.563353°N, -105.915070°W, 3722.0m\n",
      "Sno Directory: /content/input\n",
      "Ini Directory: /content/config\n",
      "==================================================\n",
      "\n",
      " Configuration files created:\n",
      "   .ini file: /content/config/watrous.ini\n",
      "   .sno files:\n",
      "     /content/input/watrous.sno\n",
      "     /content/input/watrous1.sno\n",
      "     /content/input/watrous2.sno\n",
      "     /content/input/watrous3.sno\n",
      "     /content/input/watrous4.sno\n",
      "\n",
      "Virtual slopes configured: 5\n",
      "   Slope 1: Flat (0°) -> watrous.sno\n",
      "   Slope 2: 38.0° slope facing North -> watrous1.sno\n",
      "   Slope 3: 38.0° slope facing East -> watrous2.sno\n",
      "   Slope 4: 38.0° slope facing South -> watrous3.sno\n",
      "   Slope 5: 38.0° slope facing West -> watrous4.sno\n",
      "\n",
      "SNOWPACK settings:\n",
      "   MEAS_TSS = false\n",
      "   ENFORCE_MEASURED_SNOW_HEIGHTS = false\n",
      "   NUMBER_SLOPES = 5\n",
      "\n",
      " [INFO] SNOWPACK configuration generation complete.\n",
      "[INFO] Output directory created.\n",
      "Starting SMET generation...\n",
      "Processing 1 model(s): ifs\n",
      "==================================================\n",
      "\n",
      "Processing ifs...\n",
      "Fetching ecmwf_ifs data for 39.5633531658293, -105.91506958007814 from 2024-10-30 to 2025-04-30\n",
      "Open-Meteo elevation parameter: 3722.0 (m)\n",
      "Coordinates: 39.61335372924805°N -105.85298156738281°E\n",
      "Elevation: 3722.0 m asl\n",
      "Fetched 4392 records\n",
      "SMET file created: /content/input/watrous.smet\n",
      "Records: 4392\n",
      "Period: 2024-10-30 00:00:00+00:00 to 2025-04-30 23:00:00+00:00\n",
      "\n",
      "Successfully generated 1 SMET files:\n",
      "  /content/input/watrous.smet\n",
      "\n",
      "Files saved to: /content/input\n",
      "Running SNOWPACK with config: /content/config/watrous.ini\n",
      "[i] [2025-12-23T21:12:43] ---> Start SNOWPACK in RESEARCH mode\n",
      "[i] []                 /usr/bin/snowpack compiled on Apr 29 2024 at 14:06:49\n",
      "[i] []                 Experiment : res\n",
      "[i] []                 Output dir : ./output\n",
      "\n",
      "[i] []                 Run on meteo station watrous_ifs\n",
      "[i] []                 Reading snow cover data for station watrous_ifs\n",
      "[i] []                 Finished initializing station watrous_ifs\n",
      "[i] []                 No file ./output/watrous_ifs_res-4.ini to erase\n",
      "[i] [2025-12-23T21:12:43] ---> Start simulation for watrous_ifs on 2024-10-31T23:30:00+00:00\n",
      "[i] []                 End date specified by user: 2025-04-01T00:00:00+00:00\n",
      "[i] []                 Integration step length: 30.000000 min\n",
      "[i] [2024-11-16T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 16.11.2024 00:00:00 station time\n",
      "[i] [2024-12-01T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 01.12.2024 00:00:00 station time\n",
      "[i] [2024-12-16T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 16.12.2024 00:00:00 station time\n",
      "[i] [2024-12-31T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 31.12.2024 00:00:00 station time\n",
      "[i] [2025-01-15T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 15.01.2025 00:00:00 station time\n",
      "[i] [2025-01-30T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 30.01.2025 00:00:00 station time\n",
      "[i] [2025-02-14T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 14.02.2025 00:00:00 station time\n",
      "[i] [2025-03-01T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 01.03.2025 00:00:00 station time\n",
      "[i] [2025-03-16T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 16.03.2025 00:00:00 station time\n",
      "[i] [2025-03-31T00:00:00] ---> Station watrous_ifs (5 slope(s)): advanced to 31.03.2025 00:00:00 station time\n",
      "[i] []                 Total time to read meteo data : 0.323718 s\n",
      "[i] []                 Runtime for station watrous_ifs: 32.576226 s\n",
      "\n",
      "[i] []                 STARTED  running SLF RESEARCH Snowpack Model on Tue Dec 23 21:12:43 2025\n",
      "                       ========================================================================\n",
      "                       FINISHED running SLF RESEARCH Snowpack Model on Tue Dec 23 21:13:16 2025\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_71abd307-9d46-4143-99d9-016ab5359bf2\", \"snowpack_profiles.zip\", 140183211)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ---\n",
       "    5 SNOWPACK profile files have been downloaded as **`snowpack_profiles.zip`**.\n",
       "\n",
       "    Next Step — View in niViz\n",
       "    1. Go to https://run.niviz.org\n",
       "    2. Click \"File\" → \"Open Profile\" or drag any of the downloaded files into the screen\n",
       "    3. Select any of the downloaded files:\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs4_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs3_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs2_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "   - **`watrous_ifs1_res.pro`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Step 3: Run SNOWPACK\n",
    "\n",
    "# === VERSION MARKER: 2024-12-22 v3 (with 2-day data buffer) ===\n",
    "print('[VERSION] Step 3 v3 - includes 2-day data buffer fix')\n",
    "\n",
    "\n",
    "print('[INFO] Generative Configuration Files...')\n",
    "\n",
    "# Step 3a: Generate configuration files (.ini and .sno)\n",
    "main()\n",
    "\n",
    "# Step 3b: Create output directory for SNOWPACK results\n",
    "os.makedirs(os.path.join(ini_directory, 'output'), exist_ok=True)\n",
    "print('[INFO] Output directory created.')\n",
    "\n",
    "# Step 3c: Generate SMET weather data files\n",
    "\n",
    "\n",
    "\n",
    "# --- Run Model ---\n",
    "\n",
    "\n",
    "# @markdown Run this cell to generate SMET files with the parameters above\n",
    "\n",
    "# Hardcoded output path\n",
    "# output_directory = \"/content/input\" # Commented out hardcoded path\n",
    "\n",
    "# Use sno_directory from the configuration cell\n",
    "output_directory = sno_directory  # sno directory is input folder\n",
    "\n",
    "# Model mapping\n",
    "model_mapping = {\n",
    "    \"nbm\": \"ncep_nbm_conus\",\n",
    "    \"ifs\": \"ecmwf_ifs\",\n",
    "    \"gfs\": \"gfs_global\",\n",
    "    \"nam\": \"gfs_nam_conus\",\n",
    "    \"hrrr\": \"gfs_hrrr\"\n",
    "}\n",
    "\n",
    "\n",
    "if generate_files:\n",
    "    print(\"Starting SMET generation...\")\n",
    "\n",
    "    # Parse model selection\n",
    "    selected_models = [model_selection]\n",
    "\n",
    "    # Validate and map models\n",
    "    valid_models = ['nbm', 'ifs', 'gfs', 'hrrr', 'nam']\n",
    "    selected_models = [model for model in selected_models if model in valid_models]\n",
    "\n",
    "    if not selected_models:\n",
    "        print(\"No valid models selected!\")\n",
    "        print(f\"Available models: {', '.join(valid_models)}\")\n",
    "    else:\n",
    "        print(f\"Processing {len(selected_models)} model(s): {', '.join(selected_models)}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        successful_files = []\n",
    "\n",
    "        for model in selected_models:\n",
    "            print(f\"\\nProcessing {model}...\")\n",
    "\n",
    "            # Map to Open-Meteo model name\n",
    "            openmeteo_model = model_mapping[model]\n",
    "\n",
    "            # Fetch data\n",
    "            # Buffer start date by 2 days so SNOWPACK has data before ProfileDate\n",
    "            fetch_start_dt = datetime.strptime(start_date, \"%Y-%m-%d\") - timedelta(days=2)\n",
    "            fetch_start_date = fetch_start_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            df = fetch_openmeteo_historical(\n",
    "                lat=latitude,\n",
    "                lon=longitude,\n",
    "                start_date=fetch_start_date,\n",
    "                end_date=end_date,\n",
    "                model=openmeteo_model,\n",
    "                elevation=openmeteo_elevation\n",
    "            )\n",
    "\n",
    "            if df is None or df.empty:\n",
    "                print(f\"Failed to fetch data for {model}\")\n",
    "                continue\n",
    "\n",
    "            # SNODAS Integration\n",
    "            if 'hs_source' in locals() and hs_source == \"snodas\":\n",
    "                print(f\"  Fetching SNODAS snow depth for {len(df)} records...\")\n",
    "                # Determine unique dates to fetch\n",
    "                df['date_key'] = df['timestamp'].dt.strftime(\"%Y%m%d\")\n",
    "                unique_dates = df['date_key'].unique()\n",
    "                snodas_cache = {}\n",
    "                \n",
    "                print(f\"  Retrieving SNODAS data for {len(unique_dates)} days...\")\n",
    "                for date_str in unique_dates:\n",
    "                    try:\n",
    "                        depth = get_snodas_snow_depth(latitude, longitude, date_str)\n",
    "                        if depth is not None:\n",
    "                            snodas_cache[date_str] = depth\n",
    "                    except Exception as e:\n",
    "                        print(f\"    Warning: SNODAS fetch failed for {date_str}: {e}\")\n",
    "                \n",
    "                # Map back to hourly data\n",
    "                if snodas_cache:\n",
    "                    # Create mapping series\n",
    "                    snodas_series = df['date_key'].map(snodas_cache)\n",
    "                    \n",
    "                    # Count valid mapping\n",
    "                    valid_count = snodas_series.count()\n",
    "                    if valid_count > 0:\n",
    "                        df['HS'] = snodas_series\n",
    "                        # Fill missing with 0 or keep original? Using 0 if missing for now but warn\n",
    "                        # Actually, if we want to fallback to model, we should only overwrite where valid\n",
    "                        # BUT df['HS'] might not exist yet if model didn't provide it?\n",
    "                        # OpenMeteo usually provides 'snow_depth' in meters if requested? \n",
    "                        # Wait, create_smet_from_weather_data looks for 'HS'. \n",
    "                        \n",
    "                        print(f\"   Applied SNODAS snow depth to {valid_count} records\")\n",
    "                    else:\n",
    "                        print(\"   No valid SNODAS data mapped\")\n",
    "                else:\n",
    "                    print(\"   No SNODAS data retrieved\")\n",
    "            \n",
    "            # Create output filename with simplified naming\n",
    "            output_file = os.path.join(output_directory, f\"{station_id}.smet\")\n",
    "            # could add in _{model} if wanted to specify\n",
    "\n",
    "            try:\n",
    "                # Generate SMET file\n",
    "                create_smet_from_weather_data(\n",
    "                    weather_df=df,\n",
    "                    output_path=output_file,\n",
    "                    station_id=f\"{station_id}_{model}\",\n",
    "                    station_name=f\"{station_name}_{model}\",\n",
    "                    latitude=latitude,\n",
    "                    longitude=longitude,\n",
    "                    altitude_meters=altitude_meters,\n",
    "                    timezone=timezone\n",
    "                )\n",
    "\n",
    "                print(f\"SMET file created: {output_file}\")\n",
    "                print(f\"Records: {len(df)}\")\n",
    "                print(f\"Period: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "\n",
    "                successful_files.append(output_file)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating SMET for {model}: {e}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"\\nSuccessfully generated {len(successful_files)} SMET files:\")\n",
    "        for file in successful_files:\n",
    "            print(f\"  {file}\")\n",
    "\n",
    "        if successful_files:\n",
    "            print(f\"\\nFiles saved to: {output_directory}\")\n",
    "else:\n",
    "    print(\"Generation disabled. Set 'generate_files' to True to generate SMET files.\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Results ---\n",
    "\n",
    "\n",
    "\n",
    "# Construct the path to the .ini file using variables from the configuration cell\n",
    "ini_filepath = os.path.join(ini_directory, f\"{station_id}.ini\")\n",
    "\n",
    "# Find the snowpack executable path dynamically\n",
    "try:\n",
    "    result = subprocess.run([\"which\", \"snowpack\"], capture_output=True, text=True, check=True)\n",
    "    snowpack_executable_path = result.stdout.strip()\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    snowpack_executable_path = \"snowpack\"  # Fallback to PATH lookup\n",
    "\n",
    "# Verify .ini file exists\n",
    "if not os.path.exists(ini_filepath):\n",
    "    raise FileNotFoundError(f\"Configuration file not found: {ini_filepath}\")\n",
    "\n",
    "# Run SNOWPACK with enhanced error reporting\n",
    "try:\n",
    "    print(f\"Running SNOWPACK with config: {ini_filepath}\")\n",
    "    result = subprocess.run(\n",
    "        [snowpack_executable_path, \"-c\", ini_filepath, \"-e\", snowpack_end_date],\n",
    "        cwd=ini_directory,\n",
    "        check=True,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    # If successful, print stdout\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"\\nError running SNOWPACK (exit code {e.returncode})\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"SNOWPACK STDERR:\")\n",
    "    print(e.stderr)\n",
    "    print(\"=\"*40)\n",
    "    print(\"SNOWPACK STDOUT:\")\n",
    "    print(e.stdout)\n",
    "    raise\n",
    "except FileNotFoundError:\n",
    "    print(f\"SNOWPACK executable not found: {snowpack_executable_path}\")\n",
    "    print(\"Please ensure SNOWPACK is compiled and in PATH\")\n",
    "    raise\n",
    "\n",
    "\n",
    "\n",
    "# --- Results ---\n",
    "# @title Download .pro files and Open niViz\n",
    "# @markdown # 5 files will be download.\n",
    "# @markdown # 1 = N, 2=E, 3=S, 4=W,\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Determine temp directory based on environment\n",
    "if IN_COLAB:\n",
    "    temp_dir = \"/content\"\n",
    "else:\n",
    "    # For local environments, use current directory or a temp directory\n",
    "    temp_dir = os.getcwd()\n",
    "\n",
    "# Locate all .pro files\n",
    "pro_files = glob.glob(os.path.join(ini_directory, 'output', '*.pro'))\n",
    "\n",
    "if pro_files:\n",
    "    # Copy all files to a simple location\n",
    "    downloaded_files = []\n",
    "    for pro_file in pro_files:\n",
    "        filename = os.path.basename(pro_file)\n",
    "        temp_file_path = os.path.join(temp_dir, filename)\n",
    "        shutil.copy(pro_file, temp_file_path)\n",
    "        downloaded_files.append(filename)\n",
    "\n",
    "    # Create a zip file with all .pro files\n",
    "    zip_filename = 'snowpack_profiles.zip'\n",
    "    zip_path = os.path.join(temp_dir, zip_filename)\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for filename in downloaded_files:\n",
    "            file_path = os.path.join(temp_dir, filename)\n",
    "            zipf.write(file_path, filename)\n",
    "\n",
    "    # Download the zip file (only in Colab)\n",
    "    if IN_COLAB:\n",
    "        files.download(zip_path)\n",
    "    else:\n",
    "        print(f\"Zip file created at: {zip_path}\")\n",
    "        print(f\"Files included: {', '.join(downloaded_files)}\")\n",
    "\n",
    "    # Show how to open in niViz\n",
    "    display(Markdown(f\"\"\"\n",
    "    ---\n",
    "    {len(downloaded_files)} SNOWPACK profile files have been downloaded as **`{zip_filename}`**.\n",
    "\n",
    "    Next Step — View in niViz\n",
    "    1. Go to https://run.niviz.org\n",
    "    2. Click \"File\" → \"Open Profile\" or drag any of the downloaded files into the screen\n",
    "    3. Select any of the downloaded files:\n",
    "    \"\"\"))\n",
    "\n",
    "    for filename in downloaded_files:\n",
    "        display(Markdown(f\"   - **`{filename}`**\"))\n",
    "\n",
    "else:\n",
    "    display(Markdown(\"No .pro files found in the output directory.\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SNOWPACK Simplified",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
