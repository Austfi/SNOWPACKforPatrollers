{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github",
        "vscode": {
          "languageId": "html"
        }
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Austfi/SNOWPACKforPatrollers/blob/dev/RF_Instability_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Random Forest Instability Analysis\n",
        "\n",
        "This notebook uses a Random Forest model (Mayer et al., The Cryosphere, 2022) to calculate probability of instability (P_unstable) from SNOWPACK .pro files. This provides additional avalanche risk assessment beyond the standard SNOWPACK output.\n",
        "\n",
        "**Reference**: [Mayer et al. (2022) - A random forest model to assess snow instability from simulated snow stratigraphy](https://tc.copernicus.org/articles/16/4593/2022/tc-16-4593-2022.pdf)\n",
        "\n",
        "> **\u26a0\ufe0f Note for Colab Users**: Google Colab uses Python 3.10+ by default, which may have compatibility issues with this model (trained on Python 3.7). The notebook includes automatic compatibility handling, but if you encounter errors, consider running locally with Python 3.9 for best results.\n",
        "\n",
        "## Features\n",
        "- Upload your own .pro files or use files from SNOWPACK simulations\n",
        "- Analyze single profiles for probability of instability\n",
        "- Generate time series analysis of instability evolution\n",
        "- Export daily summary statistics to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_deps",
        "outputId": "install-output"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ENVIRONMENT SETUP\n",
            "======================================================================\n",
            "Python version: 3.12.7\n",
            "Platform: macOS-10.16-x86_64-i386-64bit\n",
            "Environment: Local/Jupyter\n",
            "======================================================================\n",
            "\n",
            "Installing dependencies...\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn==0.22.2 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21.1, 0.21.2, 0.21.3, 0.22, 0.22.1, 0.22.2.post1, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.1, 0.24.2, 1.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.2.0rc1, 1.2.0, 1.2.1, 1.2.2, 1.3.0rc1, 1.3.0, 1.3.1, 1.3.2, 1.4.0rc1, 1.4.0, 1.4.1.post1, 1.4.2, 1.5.0rc1, 1.5.0, 1.5.1, 1.5.2, 1.6.0rc1, 1.6.0, 1.6.1, 1.7.0rc1, 1.7.0, 1.7.1, 1.7.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scikit-learn==0.22.2\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "======================================================================\n",
            "INSTALLATION COMPLETE\n",
            "======================================================================\n",
            "scikit-learn version: 1.5.1\n",
            "Python version: 3.12.7\n",
            "\n",
            "\u26a0 Python 3.10+ detected\n",
            "  - For best compatibility, consider using Python 3.9\n",
            "  - Compatibility layer will attempt to handle differences\n",
            "======================================================================\n",
            "\u2713 Dependencies installed successfully\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# @title Install Python dependencies for RF model\n",
        "# @markdown Installs scikit-learn and other dependencies needed for the Random Forest instability model\n",
        "# @markdown \n",
        "# @markdown **Note for Colab users**: Colab typically uses Python 3.10+. The compatibility layer in this notebook handles sklearn version differences automatically.\n",
        "\n",
        "import sys\n",
        "import platform\n",
        "import os\n",
        "\n",
        "# Detect if we're in Colab\n",
        "IN_COLAB = os.path.exists(\"/content\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ENVIRONMENT SETUP\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Python version: {sys.version.split()[0]}\")\n",
        "print(f\"Platform: {platform.platform()}\")\n",
        "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local/Jupyter'}\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "# Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install numpy pandas matplotlib joblib scikit-learn==0.22.2\n",
        "\n",
        "import sklearn\n",
        "\n",
        "print()\n",
        "print(\"=\"*70)\n",
        "print(\"INSTALLATION COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"Python version: {sys.version.split()[0]}\")\n",
        "print()\n",
        "\n",
        "# Check compatibility\n",
        "python_version = sys.version_info\n",
        "if IN_COLAB:\n",
        "    if python_version.major == 3 and python_version.minor >= 10:\n",
        "        print(\"\u26a0 Colab Environment Detected\")\n",
        "        print(\"  - Python 3.10+ detected (Colab default)\")\n",
        "        print(\"  - Compatibility layer will handle sklearn version differences\")\n",
        "        print(\"  - If model loading fails, the notebook will provide detailed guidance\")\n",
        "    else:\n",
        "        print(\"\u2713 Compatible Python version detected\")\n",
        "else:\n",
        "    if python_version.major == 3 and python_version.minor >= 10:\n",
        "        print(\"\u26a0 Python 3.10+ detected\")\n",
        "        print(\"  - For best compatibility, consider using Python 3.9\")\n",
        "        print(\"  - Compatibility layer will attempt to handle differences\")\n",
        "    elif python_version.major == 3 and python_version.minor == 9:\n",
        "        print(\"\u2713 Python 3.9 detected - optimal compatibility\")\n",
        "    elif python_version.major == 3 and python_version.minor <= 8:\n",
        "        print(\"\u2713 Compatible Python version detected\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\u2713 Dependencies installed successfully\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "download_rf",
        "outputId": "download-output"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u26a0 Error importing helper modules: No module named 'get_RF'\n",
            "Make sure the RF model download cell ran successfully.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'get_RF'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mget_RF\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mreadProfile\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplt_RF\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'get_RF'"
          ]
        }
      ],
      "source": [
        "# @title Patch plt_RF.py and load the RF model\n",
        "# @markdown Fixes syntax warnings and loads the Random Forest model with multiple compatibility strategies\n",
        "\n",
        "import sys\n",
        "import pathlib\n",
        "import joblib\n",
        "import warnings\n",
        "import importlib\n",
        "import re\n",
        "\n",
        "# Determine RF directory based on environment\n",
        "if os.path.exists(\"/content\"):\n",
        "    rf_dir = pathlib.Path(\"/content/rf_instability\").resolve()\n",
        "else:\n",
        "    rf_dir = pathlib.Path(\"./rf_instability\").resolve()\n",
        "\n",
        "if str(rf_dir) not in sys.path:\n",
        "    sys.path.insert(0, str(rf_dir))\n",
        "\n",
        "# Fix syntax warnings in plt_RF.py more thoroughly\n",
        "def patch_plt_RF():\n",
        "    \"\"\"Patch plt_RF.py to fix invalid escape sequences\"\"\"\n",
        "    plt_RF_path = rf_dir / 'plt_RF.py'\n",
        "    if plt_RF_path.exists():\n",
        "        try:\n",
        "            with open(plt_RF_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "            \n",
        "            # Fix invalid escape sequences using regex to catch all variations\n",
        "            # Pattern: $...\\m...$ (mathregular or mathrm)\n",
        "            content = re.sub(r'\\$([^$]*?)\\\\([mM])([^$]*?)\\$', r'$\\1\\\\\\2\\3$', content)\n",
        "            \n",
        "            # Also fix specific known patterns\n",
        "            content = content.replace('\\\\mathregular', r'\\mathregular')\n",
        "            content = content.replace('\\\\mathrm', r'\\mathrm')\n",
        "            content = content.replace('$P_\\\\mathrm{unstable}$', r'$P_\\mathrm{unstable}$')\n",
        "            content = content.replace('$\\\\mathregular{P_{unstable}}$', r'$\\mathregular{P_{unstable}}$')\n",
        "                \n",
        "            with open(plt_RF_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            print(\"\u2713 Patched plt_RF.py to fix syntax warnings\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0 Could not patch plt_RF.py: {e}\")\n",
        "            return False\n",
        "    return False\n",
        "\n",
        "# Patch plt_RF.py before importing\n",
        "patch_plt_RF()\n",
        "\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import get_RF\n",
        "    import readProfile\n",
        "    import plt_RF\n",
        "    print(\"\u2713 Helper modules imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"\u26a0 Error importing helper modules: {e}\")\n",
        "    print(\"Make sure the RF model download cell ran successfully.\")\n",
        "    raise\n",
        "\n",
        "MODEL_PATH = rf_dir / 'RF_instability_model.sav'\n",
        "feature_names = ['viscdefrate','rcflat','sphericity','grainsize','penetrationdepth','slab_rhogs']\n",
        "\n",
        "def load_rf_model_compat(model_path):\n",
        "    \"\"\"\n",
        "    Load RF model with multiple compatibility strategies.\n",
        "    \n",
        "    Strategy 1: Try standard joblib.load (should work with sklearn 0.22.2)\n",
        "    Strategy 2: Monkey-patch sklearn tree module to accept old format\n",
        "    Strategy 3: Patch tree nodes after loading\n",
        "    \"\"\"\n",
        "    import sklearn\n",
        "    from sklearn.tree import _tree\n",
        "    \n",
        "    # Strategy 1: Try standard load first\n",
        "    try:\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings('ignore', category=UserWarning)\n",
        "            model = joblib.load(model_path)\n",
        "        \n",
        "        # Verify nodes are compatible\n",
        "        if hasattr(model, 'estimators_'):\n",
        "            for estimator in model.estimators_:\n",
        "                if hasattr(estimator, 'tree_'):\n",
        "                    tree = estimator.tree_\n",
        "                    if hasattr(tree, 'nodes') and tree.nodes is not None:\n",
        "                        if 'missing_go_to_left' not in tree.nodes.dtype.names:\n",
        "                            # Need to patch\n",
        "                            break\n",
        "            else:\n",
        "                # All trees are compatible\n",
        "                return model\n",
        "        \n",
        "        # If we get here, need to patch nodes\n",
        "        print(\"\u26a0 Patching tree nodes for compatibility...\")\n",
        "        for estimator in model.estimators_:\n",
        "            if hasattr(estimator, 'tree_'):\n",
        "                tree = estimator.tree_\n",
        "                if hasattr(tree, 'nodes') and tree.nodes is not None:\n",
        "                    old_nodes = tree.nodes\n",
        "                    if 'missing_go_to_left' not in old_nodes.dtype.names:\n",
        "                        new_dtype = np.dtype([\n",
        "                            ('left_child', '<i8'),\n",
        "                            ('right_child', '<i8'),\n",
        "                            ('feature', '<i8'),\n",
        "                            ('threshold', '<f8'),\n",
        "                            ('impurity', '<f8'),\n",
        "                            ('n_node_samples', '<i8'),\n",
        "                            ('weighted_n_node_samples', '<f8'),\n",
        "                            ('missing_go_to_left', 'u1')\n",
        "                        ])\n",
        "                        new_nodes = np.zeros(len(old_nodes), dtype=new_dtype)\n",
        "                        for field in old_nodes.dtype.names:\n",
        "                            new_nodes[field] = old_nodes[field]\n",
        "                        new_nodes['missing_go_to_left'] = 0\n",
        "                        tree.nodes = new_nodes\n",
        "        \n",
        "        return model\n",
        "        \n",
        "    except ValueError as e:\n",
        "        if \"incompatible dtype\" in str(e) or \"missing_go_to_left\" in str(e):\n",
        "            # Strategy 2: Monkey-patch sklearn's tree module\n",
        "            print(\"\u26a0 Standard load failed, trying monkey-patch approach...\")\n",
        "            \n",
        "            original_check = getattr(_tree, '_check_node_ndarray', None)\n",
        "            \n",
        "            def patched_check_node_ndarray(node_array, *args, **kwargs):\n",
        "                \"\"\"Patch to accept old format nodes (supports sklearn >=1.4 signature).\"\"\"\n",
        "                expected_dtype = kwargs.get('expected_dtype')\n",
        "                if expected_dtype is None and args:\n",
        "                    expected_dtype = args[0]\n",
        "\n",
        "                if node_array.dtype.names and 'missing_go_to_left' not in node_array.dtype.names:\n",
        "                    new_dtype = np.dtype([\n",
        "                        ('left_child', '<i8'),\n",
        "                        ('right_child', '<i8'),\n",
        "                        ('feature', '<i8'),\n",
        "                        ('threshold', '<f8'),\n",
        "                        ('impurity', '<f8'),\n",
        "                        ('n_node_samples', '<i8'),\n",
        "                        ('weighted_n_node_samples', '<f8'),\n",
        "                        ('missing_go_to_left', 'u1')\n",
        "                    ])\n",
        "\n",
        "                    new_nodes = np.zeros(node_array.shape, dtype=new_dtype)\n",
        "                    for field in node_array.dtype.names:\n",
        "                        new_nodes[field] = node_array[field]\n",
        "                    new_nodes['missing_go_to_left'] = 0\n",
        "                    node_array = new_nodes\n",
        "\n",
        "                if expected_dtype is not None and node_array.dtype != expected_dtype:\n",
        "                    try:\n",
        "                        node_array = node_array.astype(expected_dtype)\n",
        "                    except TypeError:\n",
        "                        pass\n",
        "\n",
        "                if original_check:\n",
        "                    return original_check(node_array, *args, **kwargs)\n",
        "                return node_array\n",
        "            \n",
        "            # Apply monkey-patch\n",
        "            _tree._check_node_ndarray = patched_check_node_ndarray\n",
        "            \n",
        "            try:\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.filterwarnings('ignore', category=UserWarning)\n",
        "                    model = joblib.load(model_path)\n",
        "                \n",
        "                # Patch all tree nodes to ensure compatibility\n",
        "                if hasattr(model, 'estimators_'):\n",
        "                    for estimator in model.estimators_:\n",
        "                        if hasattr(estimator, 'tree_'):\n",
        "                            tree = estimator.tree_\n",
        "                            if hasattr(tree, 'nodes') and tree.nodes is not None:\n",
        "                                old_nodes = tree.nodes\n",
        "                                if 'missing_go_to_left' not in old_nodes.dtype.names:\n",
        "                                    new_dtype = np.dtype([\n",
        "                                        ('left_child', '<i8'),\n",
        "                                        ('right_child', '<i8'),\n",
        "                                        ('feature', '<i8'),\n",
        "                                        ('threshold', '<f8'),\n",
        "                                        ('impurity', '<f8'),\n",
        "                                        ('n_node_samples', '<i8'),\n",
        "                                        ('weighted_n_node_samples', '<f8'),\n",
        "                                        ('missing_go_to_left', 'u1')\n",
        "                                    ])\n",
        "                                    new_nodes = np.zeros(len(old_nodes), dtype=new_dtype)\n",
        "                                    for field in old_nodes.dtype.names:\n",
        "                                        new_nodes[field] = old_nodes[field]\n",
        "                                    new_nodes['missing_go_to_left'] = 0\n",
        "                                    tree.nodes = new_nodes\n",
        "                \n",
        "                return model\n",
        "            finally:\n",
        "                # Restore original function\n",
        "                if original_check:\n",
        "                    _tree._check_node_ndarray = original_check\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "try:\n",
        "    model = load_rf_model_compat(MODEL_PATH)\n",
        "    print(f\"\u2713 Loaded RF model: {MODEL_PATH.name}\")\n",
        "    \n",
        "    if not hasattr(model, \"estimator\"):\n",
        "        model.estimator = DecisionTreeClassifier(\n",
        "            criterion=model.criterion,\n",
        "            max_depth=model.max_depth,\n",
        "            min_samples_split=model.min_samples_split,\n",
        "            min_samples_leaf=model.min_samples_leaf,\n",
        "            min_weight_fraction_leaf=model.min_weight_fraction_leaf,\n",
        "            max_features=model.max_features,\n",
        "            max_leaf_nodes=model.max_leaf_nodes,\n",
        "            min_impurity_decrease=model.min_impurity_decrease,\n",
        "            random_state=model.random_state,\n",
        "            splitter=\"best\",\n",
        "            class_weight=model.class_weight,\n",
        "            ccp_alpha=getattr(model, \"ccp_alpha\", 0.0),\n",
        "        )\n",
        "    # Colab-specific success message\n",
        "    import os\n",
        "    if os.path.exists(\"/content\"):\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"\u2705 SUCCESS - Model loaded in Colab environment\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"The compatibility layer successfully handled the sklearn version differences.\")\n",
        "        print(\"You can now proceed with analyzing your .pro files.\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\u2757 Model load failed with all compatibility strategies.\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"COMPATIBILITY ISSUE EXPLANATION\")\n",
        "    print(\"=\"*70)\n",
        "    import sklearn\n",
        "    import os\n",
        "    \n",
        "    IN_COLAB = os.path.exists(\"/content\")\n",
        "    python_version = sys.version_info\n",
        "    \n",
        "    if IN_COLAB:\n",
        "        colab_note = \"\"\"\n",
        "\u26a0\ufe0f COLAB ENVIRONMENT DETECTED\n",
        "\n",
        "Colab uses Python 3.10+ by default, which has stricter pickle protocols\n",
        "than Python 3.7 (where the model was trained). The compatibility layer\n",
        "attempted multiple strategies but all failed.\n",
        "\n",
        "RECOMMENDED SOLUTION FOR COLAB:\n",
        "\"\"\"\n",
        "        solutions = \"\"\"\n",
        "1. RESTART COLAB RUNTIME WITH PYTHON 3.9 (if available)\n",
        "   - Runtime \u2192 Change runtime type \u2192 Python version \u2192 3.9\n",
        "   - Re-run all cells\n",
        "   - This provides the best compatibility\n",
        "\n",
        "2. USE LOCAL ENVIRONMENT (RECOMMENDED FOR RELIABILITY)\n",
        "   - Install locally: conda create -n rf_model python=3.9 scikit-learn=0.22.2\n",
        "   - Or use Python 3.8: conda create -n rf_model python=3.8 scikit-learn=0.22.2\n",
        "   - More reliable than Colab's Python 3.10+\n",
        "\n",
        "3. DOWNLOAD MODEL AND USE LOCAL JUPYTER\n",
        "   - Download the notebook and model files\n",
        "   - Run in local environment with Python 3.9\n",
        "   - Best long-term solution\n",
        "\n",
        "4. WAIT FOR MODEL UPDATE\n",
        "   - Contact maintainers for skops-compatible version\n",
        "   - Repository: https://code.wsl.ch/mayers/random_forest_snow_instability_model\n",
        "\n",
        "5. USE COMPATIBILITY CONVERSION (if you have access to Python 3.7/3.9)\n",
        "   - Convert model to skops format in compatible environment\n",
        "   - Then load in Colab using: pip install skops; model = skops.load('model.skops')\n",
        "\"\"\"\n",
        "    else:\n",
        "        colab_note = \"\"\n",
        "        solutions = \"\"\"\n",
        "SOLUTION OPTIONS (ranked by preference):\n",
        "\n",
        "1. USE PYTHON 3.8 OR 3.9 (RECOMMENDED)\n",
        "   - Python 3.8/3.9 + sklearn 0.22.2 generally works better than 3.10+\n",
        "   - Less strict pickle protocol, better compatibility\n",
        "   - Command: conda create -n rf_model python=3.9 scikit-learn=0.22.2\n",
        "\n",
        "2. USE EXACT ORIGINAL ENVIRONMENT\n",
        "   - Python 3.7 + sklearn 0.22.1 (exact match)\n",
        "   - Command: conda create -n rf_model python=3.7 scikit-learn=0.22.1\n",
        "\n",
        "3. CONVERT MODEL TO SKOPS FORMAT (requires original environment)\n",
        "   - Install skops in original environment: pip install skops\n",
        "   - Convert: import skops; skops.dump(model, 'model.skops')\n",
        "   - Load in any environment: model = skops.load('model.skops')\n",
        "\n",
        "4. CONTACT MODEL MAINTAINERS\n",
        "   - Request updated model file compatible with newer sklearn\n",
        "   - Repository: https://code.wsl.ch/mayers/random_forest_snow_instability_model\n",
        "\n",
        "5. RETRAIN MODEL (if training data available)\n",
        "   - Retrain with current sklearn version for full compatibility\n",
        "\"\"\"\n",
        "    \n",
        "    error_msg = f\"\"\"\n",
        "The RF model was saved with scikit-learn 0.22.1 (Python 3.7) which uses\n",
        "an older tree node structure without the 'missing_go_to_left' field.\n",
        "\n",
        "Newer sklearn versions (even 0.22.2 on Python 3.10+) expect this field during\n",
        "unpickling, causing a dtype mismatch error.\n",
        "{colab_note}{solutions}\n",
        "\n",
        "Current environment:\n",
        "  - Environment: {'Google Colab' if IN_COLAB else 'Local/Jupyter'}\n",
        "  - Python: {sys.version.split()[0]} ({python_version.major}.{python_version.minor})\n",
        "  - scikit-learn: {sklearn.__version__}\n",
        "  - Compatibility strategies attempted: All (standard load, monkey-patch, node patching)\n",
        "    \"\"\"\n",
        "    print(error_msg)\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nOriginal error:\\n{e}\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    if IN_COLAB:\n",
        "        print(\"\\n\ud83d\udca1 TIP: For best results in Colab, consider:\")\n",
        "        print(\"   1. Using a local Python 3.9 environment\")\n",
        "        print(\"   2. Converting the model to skops format\")\n",
        "        print(\"   3. Contacting model maintainers for updated version\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting"
      },
      "source": [
        "## Troubleshooting: Model Loading Issues\n",
        "\n",
        "If you encounter model loading errors in Colab, try these solutions:\n",
        "\n",
        "**Option 1: Restart Runtime**\n",
        "- Runtime \u2192 Restart runtime\n",
        "- Re-run all cells\n",
        "- Sometimes clears Python caching issues\n",
        "\n",
        "**Option 2: Use Local Environment (Recommended)**\n",
        "```bash\n",
        "# Create environment\n",
        "conda create -n rf_model python=3.9 scikit-learn=0.22.2 numpy pandas matplotlib joblib\n",
        "conda activate rf_model\n",
        "\n",
        "# Install Jupyter\n",
        "pip install jupyter notebook\n",
        "\n",
        "# Run notebook\n",
        "jupyter notebook RF_Instability_Analysis.ipynb\n",
        "```\n",
        "\n",
        "**Option 3: Use Python 3.9 Runtime (if available)**\n",
        "- Runtime \u2192 Change runtime type\n",
        "- Set Python version to 3.9\n",
        "- Re-run all cells\n",
        "\n",
        "**Option 4: Download and Run Locally**\n",
        "- File \u2192 Download \u2192 Download .ipynb\n",
        "- Run in local Python 3.9 environment\n",
        "- More reliable than Colab for this model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_section"
      },
      "source": [
        "## Upload .pro File\n",
        "\n",
        "Upload your SNOWPACK .pro file below. You can:\n",
        "- Upload a file from your computer (Colab)\n",
        "- Provide a path to a file already in the environment\n",
        "- Use a file from a SNOWPACK simulation output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upload_pro",
        "outputId": "upload-output"
      },
      "outputs": [],
      "source": [
        "# @title Upload or specify .pro file\n",
        "# @markdown Choose how to provide your .pro file\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# @markdown ### File Input Method\n",
        "file_input_method = \"path\"  # @param [\"upload\", \"path\", \"glob\"]\n",
        "\n",
        "# @markdown ### If using \"path\", specify the file path:\n",
        "file_path = \"../input_example/WFJ2_2017.pro\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### If using \"glob\", specify a pattern (e.g., \"./output/*.pro\"):\n",
        "glob_pattern = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Handle file upload/selection\n",
        "pro_file = None\n",
        "\n",
        "if file_input_method == \"upload\":\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            # Get the first uploaded file\n",
        "            pro_file = list(uploaded.keys())[0]\n",
        "            print(f\"\u2713 Uploaded file: {pro_file}\")\n",
        "        else:\n",
        "            print(\"\u26a0 No file uploaded\")\n",
        "    except ImportError:\n",
        "        print(\"\u26a0 File upload not available (not in Colab). Use 'path' or 'glob' method instead.\")\n",
        "        print(\"You can drag and drop files in Jupyter Lab, or use the 'path' method.\")\n",
        "\n",
        "elif file_input_method == \"path\":\n",
        "    if file_path and os.path.exists(file_path):\n",
        "        pro_file = file_path\n",
        "        print(f\"\u2713 Using file: {pro_file}\")\n",
        "    else:\n",
        "        print(f\"\u26a0 File not found: {file_path}\")\n",
        "\n",
        "elif file_input_method == \"glob\":\n",
        "    if glob_pattern:\n",
        "        matches = glob.glob(glob_pattern)\n",
        "        if matches:\n",
        "            pro_file = matches[0]\n",
        "            print(f\"\u2713 Found {len(matches)} file(s), using: {pro_file}\")\n",
        "            if len(matches) > 1:\n",
        "                print(f\"  Other matches: {matches[1:]}\")\n",
        "        else:\n",
        "            print(f\"\u26a0 No files found matching: {glob_pattern}\")\n",
        "    else:\n",
        "        print(\"\u26a0 No glob pattern specified\")\n",
        "\n",
        "if pro_file and os.path.exists(pro_file):\n",
        "    print(f\"\\n\u2713 Ready to analyze: {pro_file}\")\n",
        "    file_size = os.path.getsize(pro_file) / (1024 * 1024)  # Size in MB\n",
        "    print(f\"  File size: {file_size:.2f} MB\")\n",
        "else:\n",
        "    print(\"\\n\u26a0 No valid .pro file selected. Please upload or specify a file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "single_profile"
      },
      "source": [
        "## Single Profile Analysis\n",
        "\n",
        "Analyze a single profile from your .pro file for probability of instability at a specific date and time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "single_profile_analysis",
        "outputId": "single-output"
      },
      "outputs": [],
      "source": [
        "# @title Single Profile: Calculate P_unstable\n",
        "# @markdown Analyze a single SNOWPACK profile for probability of instability\n",
        "\n",
        "import datetime\n",
        "\n",
        "# @markdown ## Analysis Parameters\n",
        "slope_angle = 0  # @param {type:\"number\", min:0, max:90}\n",
        "# @markdown Date/time to analyze (format: YYYY-MM-DD HH:MM)\n",
        "analysis_date = \"2017-02-01 11:00\"  # @param {type:\"string\"}\n",
        "\n",
        "if not pro_file or not os.path.exists(pro_file):\n",
        "    print(\"\u26a0 No .pro file selected. Please run the upload cell first.\")\n",
        "else:\n",
        "    # Parse date\n",
        "    try:\n",
        "        timestamp = datetime.datetime.strptime(analysis_date, \"%Y-%m-%d %H:%M\")\n",
        "    except ValueError:\n",
        "        print(f\"\u26a0 Date format error. Using default: 2017-02-01 11:00\")\n",
        "        timestamp = datetime.datetime(2017, 2, 1, 11, 0)\n",
        "\n",
        "    # Read profile and calculate P_unstable\n",
        "    try:\n",
        "        prof = readProfile.read_profile(pro_file, timestamp, remove_soil=True)\n",
        "        df_prof = get_RF.create_RFprof(prof, slope_angle, model)\n",
        "        \n",
        "        # Quick sanity check: probabilities within [0,1]\n",
        "        assert df_prof['P_unstable'].between(0, 1).all(), \"P_unstable values must be between 0 and 1\"\n",
        "        \n",
        "        print(f\"\u2713 Profile loaded and analyzed\")\n",
        "        print(f\"  File: {os.path.basename(pro_file)}\")\n",
        "        print(f\"  Date: {timestamp}\")\n",
        "        print(f\"  Slope angle: {slope_angle}\u00b0\")\n",
        "        print(f\"  Max P_unstable: {df_prof['P_unstable'].max():.3f}\")\n",
        "        print(f\"  Depth at max P_unstable: {df_prof.loc[df_prof['P_unstable'].idxmax(), 'layer_top']:.2f} m\")\n",
        "        \n",
        "        # Plot\n",
        "        fig, ax = plt.subplots(figsize=(5, 6))\n",
        "        plt_RF.plot_sp_single_P0(fig, ax, df_prof, var='P_unstable', colorbar=True)\n",
        "        plt.title(f\"P_unstable Analysis\\n{os.path.basename(pro_file)} - {timestamp.strftime('%Y-%m-%d %H:%M')}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing profile: {e}\")\n",
        "        print(f\"\\nTroubleshooting:\")\n",
        "        print(f\"  - Check that the date '{timestamp}' exists in the .pro file\")\n",
        "        print(f\"  - Verify the .pro file format is correct\")\n",
        "        print(f\"  - Try a different date from the file\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "time_series"
      },
      "source": [
        "## Time Series Analysis\n",
        "\n",
        "Analyze how P_unstable evolves over time for a seasonal period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "time_series_analysis",
        "outputId": "timeseries-output"
      },
      "outputs": [],
      "source": [
        "# @title Time Series: Daily Evolution of P_unstable\n",
        "# @markdown Analyze how P_unstable evolves over time for a seasonal period\n",
        "\n",
        "import datetime\n",
        "\n",
        "# @markdown ## Time Period\n",
        "year = 2017  # @param {type:\"integer\"}\n",
        "start_month = 12  # @param {type:\"integer\", min:1, max:12}\n",
        "start_day = 1  # @param {type:\"integer\", min:1, max:31}\n",
        "end_month = 4  # @param {type:\"integer\", min:1, max:12}\n",
        "end_day = 1  # @param {type:\"integer\", min:1, max:31}\n",
        "\n",
        "# @markdown ## Analysis Parameters\n",
        "slope_angle_ts = 0  # @param {type:\"number\", min:0, max:90}\n",
        "\n",
        "if not pro_file or not os.path.exists(pro_file):\n",
        "    print(\"\u26a0 No .pro file selected. Please run the upload cell first.\")\n",
        "else:\n",
        "    # Create date range\n",
        "    start = datetime.datetime(year-1 if start_month == 12 else year, start_month, start_day, 12, 0)\n",
        "    stop = datetime.datetime(year, end_month, end_day, 12, 0)\n",
        "\n",
        "    print(f\"Analyzing time series from {start.date()} to {stop.date()}\")\n",
        "    print(f\"Slope angle: {slope_angle_ts}\u00b0\")\n",
        "\n",
        "    # Read all profiles from file\n",
        "    profiles = readProfile.read_profile(pro_file, remove_soil=True)\n",
        "    dates = pd.date_range(start, stop, freq='D')\n",
        "\n",
        "    df_list = []\n",
        "    missing_dates = []\n",
        "\n",
        "    for ts in dates:\n",
        "        if ts in profiles['data'].keys():\n",
        "            prof = profiles['data'][ts]\n",
        "            if (len(prof.keys()) == 0) or (len(prof['height']) == 0):\n",
        "                # Empty profile - create placeholder\n",
        "                df0 = pd.DataFrame(columns=['P_unstable','layer_top','density','hardness','graintype',\n",
        "                                            'viscdefrate','rcflat','sphericity','grainsize',\n",
        "                                            'penetrationdepth','slab_rhogs','HS'], index=[0])\n",
        "                df0['HS'] = 0.0\n",
        "            else:\n",
        "                df0 = get_RF.create_RFprof(prof, slope_angle_ts, model)\n",
        "                df0['HS'] = df0['layer_top'].iloc[-1]\n",
        "            df0.insert(0, 'datetime', ts)\n",
        "            df_list.append(df0)\n",
        "        else:\n",
        "            missing_dates.append(ts)\n",
        "\n",
        "    if missing_dates:\n",
        "        print(f\"\u26a0 Warning: {len(missing_dates)} dates not found in profile file\")\n",
        "\n",
        "    if not df_list:\n",
        "        print(\"\u26a0 No data found for the specified date range\")\n",
        "        print(\"Try adjusting the date range or check the .pro file contents\")\n",
        "    else:\n",
        "        df_evo = pd.concat(df_list, ignore_index=True)\n",
        "        \n",
        "        print(f\"\u2713 Analyzed {len(df_list)} profiles\")\n",
        "        \n",
        "        # Plot\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        plt_RF.plot_evo_SP(df_evo, fig, ax, start, stop, var='P_unstable', colorbar=True, resolution='D')\n",
        "        plt.title(f\"Daily Evolution of P_unstable\\n{os.path.basename(pro_file)} - Slope: {slope_angle_ts}\u00b0\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export_csv"
      },
      "source": [
        "## Export Daily Summary CSV\n",
        "\n",
        "Generate a CSV file with daily summary statistics for easy analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "export_csv_analysis",
        "outputId": "export-output"
      },
      "outputs": [],
      "source": [
        "# @title Export Daily Summary CSV\n",
        "# @markdown Generate a CSV file with daily summary statistics for easy analysis\n",
        "\n",
        "# @markdown ## Export Parameters\n",
        "export_year = 2017  # @param {type:\"integer\"}\n",
        "export_start_month = 12  # @param {type:\"integer\", min:1, max:12}\n",
        "export_start_day = 1  # @param {type:\"integer\", min:1, max:31}\n",
        "export_end_month = 4  # @param {type:\"integer\", min:1, max:12}\n",
        "export_end_day = 1  # @param {type:\"integer\", min:1, max:31}\n",
        "export_slope_angle = 0  # @param {type:\"number\", min:0, max:90}\n",
        "\n",
        "if not pro_file or not os.path.exists(pro_file):\n",
        "    print(\"\u26a0 No .pro file selected. Please run the upload cell first.\")\n",
        "else:\n",
        "    start = pd.Timestamp(export_year-1 if export_start_month == 12 else export_year, export_start_month, export_start_day, 12, 0)\n",
        "    stop = pd.Timestamp(export_year, export_end_month, export_end_day, 12, 0)\n",
        "\n",
        "    print(f\"Generating daily summary from {start.date()} to {stop.date()}\")\n",
        "    print(f\"Slope angle: {export_slope_angle}\u00b0\")\n",
        "\n",
        "    profiles = readProfile.read_profile(pro_file, remove_soil=True)\n",
        "    rows = []\n",
        "\n",
        "    for ts in pd.date_range(start, stop, freq='D'):\n",
        "        prof = profiles['data'].get(ts)\n",
        "        if not prof or len(prof.get('height', [])) == 0:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            dfi = get_RF.create_RFprof(prof, export_slope_angle, model)\n",
        "            rows.append({\n",
        "                'datetime': ts,\n",
        "                'HS': float(dfi['layer_top'].iloc[-1]),\n",
        "                'P_unstable_max': float(dfi['P_unstable'].max()),\n",
        "                'z_Pmax': float(dfi.loc[dfi['P_unstable'].idxmax(), 'layer_top']),\n",
        "                'P_unstable_mean': float(dfi['P_unstable'].mean())\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0 Error processing {ts}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if rows:\n",
        "        out = pd.DataFrame(rows).sort_values('datetime')\n",
        "        \n",
        "        # Determine output path\n",
        "        if os.path.exists(\"/content\"):\n",
        "            out_path = '/content/p_unstable_daily.csv'\n",
        "        else:\n",
        "            out_path = './p_unstable_daily.csv'\n",
        "        \n",
        "        out.to_csv(out_path, index=False)\n",
        "        \n",
        "        print(f\"\\n\u2713 Daily summary exported to: {out_path}\")\n",
        "        print(f\"  Records: {len(out)}\")\n",
        "        print(f\"\\nPreview:\")\n",
        "        print(out.head(10).to_string(index=False))\n",
        "        \n",
        "        # Download in Colab\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            files.download(out_path)\n",
        "            print(\"\\n\u2713 File downloaded\")\n",
        "        except ImportError:\n",
        "            print(f\"\\nFile saved at: {out_path}\")\n",
        "    else:\n",
        "        print(\"\u26a0 No data found for the specified date range\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}